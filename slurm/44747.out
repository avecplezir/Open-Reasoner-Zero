
======== GPU REPORT ========

==============NVSMI LOG==============

Timestamp                                 : Mon Jul 14 15:54:12 2025
Driver Version                            : 570.133.20
CUDA Version                              : 12.8

Attached GPUs                             : 4
GPU 00000000:4E:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes                   : None

GPU 00000000:5F:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes                   : None

GPU 00000000:CB:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes                   : None

GPU 00000000:DB:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes                   : None

Mon Jul 14 15:54:13 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:4E:00.0 Off |                    0 |
| N/A   39C    P0             74W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  |   00000000:5F:00.0 Off |                    0 |
| N/A   38C    P0             72W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  |   00000000:CB:00.0 Off |                    0 |
| N/A   39C    P0             71W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  |   00000000:DB:00.0 Off |                    0 |
| N/A   39C    P0             71W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
2025-07-14 15:54:14,689	INFO usage_lib.py:472 -- Usage stats collection is enabled. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.
2025-07-14 15:54:14,689	INFO scripts.py:865 -- Local node IP: 10.224.3.42
2025-07-14 15:54:16,938	SUCC scripts.py:902 -- --------------------
2025-07-14 15:54:16,938	SUCC scripts.py:903 -- Ray runtime started.
2025-07-14 15:54:16,939	SUCC scripts.py:904 -- --------------------
2025-07-14 15:54:16,939	INFO scripts.py:906 -- Next steps
2025-07-14 15:54:16,939	INFO scripts.py:909 -- To add another node to this Ray cluster, run
2025-07-14 15:54:16,939	INFO scripts.py:912 --   ray start --address='10.224.3.42:36816'
2025-07-14 15:54:16,939	INFO scripts.py:921 -- To connect to this Ray cluster:
2025-07-14 15:54:16,939	INFO scripts.py:923 -- import ray
2025-07-14 15:54:16,939	INFO scripts.py:924 -- ray.init(_node_ip_address='10.224.3.42')
2025-07-14 15:54:16,939	INFO scripts.py:955 -- To terminate the Ray runtime, run
2025-07-14 15:54:16,939	INFO scripts.py:956 --   ray stop
2025-07-14 15:54:16,939	INFO scripts.py:959 -- To view the status of the cluster, use
2025-07-14 15:54:16,939	INFO scripts.py:960 --   ray status
2025-07-14 15:54:16,940	INFO scripts.py:1076 -- --block
2025-07-14 15:54:16,940	INFO scripts.py:1077 -- This command will now block forever until terminated by a signal.
2025-07-14 15:54:16,940	INFO scripts.py:1080 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.
[2025-07-14 15:54:25,197 W 1558898 1558898] global_state_accessor.cc:429: Retrying to get node with node ID a1a15f3fd279c5bed8f8360c2448a9163471d1a6a6aefeca0ed24f64
2025-07-14 15:54:24,962	INFO scripts.py:1047 -- Local node IP: 10.224.3.43
2025-07-14 15:54:26,200	SUCC scripts.py:1063 -- --------------------
2025-07-14 15:54:26,200	SUCC scripts.py:1064 -- Ray runtime started.
2025-07-14 15:54:26,200	SUCC scripts.py:1065 -- --------------------
2025-07-14 15:54:26,200	INFO scripts.py:1067 -- To terminate the Ray runtime, run
2025-07-14 15:54:26,201	INFO scripts.py:1068 --   ray stop
2025-07-14 15:54:26,201	INFO scripts.py:1076 -- --block
2025-07-14 15:54:26,201	INFO scripts.py:1077 -- This command will now block forever until terminated by a signal.
2025-07-14 15:54:26,201	INFO scripts.py:1080 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.
[2025-07-14 15:54:54,625] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
math_verify is not installed in this environment
2025-07-14 15:54:57.216 | INFO     | __main__:<module>:125 - --------- config key ---------        ------ value ------
seed                                  42
ref_num_nodes                         8
ref_num_gpus_per_node                 1
reward_num_nodes                      1
reward_num_gpus_per_node              2
actor_num_nodes                       8
actor_num_gpus_per_node               1
critic_num_nodes                      8
critic_num_gpus_per_node              1
colocate_critic_reward                True
colocate_actor_ref                    True
colocate_all                          True
vllm_num_engines                      8
vllm_tensor_parallel_size             1
vllm_sync_backend                     nccl
local_rank                            -1
pretrain                              /home/a/anokhin/links/scratch/Qwen2.5-0.5B
critic_pretrain                       /home/a/anokhin/links/scratch/Qwen2.5-0.5B
reward_pretrain                       <class 'NoneType'>
ckpt_path                             orz_ckpt/orz_0p5b_ppo
save_path                             orz_ckpt/orz_0p5b_ppo
tensorboard_log_dir                   orz_logs/orz_0p5b_ppo
prompt_data                           <class 'omegaconf.listconfig.ListConfig'>
load_checkpoint                       False
zero_stage                            3
bf16                                  True
zpg                                   1
adam_offload                          False
flash_attn                            True
grad_accum_dtype                      <class 'NoneType'>
disable_trace_cache                   False
gradient_checkpointing                True
gradient_checkpointing_use_reentrant  False
disable_fast_tokenizer                False
target_modules                        all-linear
enable_prefix_caching                 True
enable_chunked_prefill                False
max_num_batched_tokens                2048
enforce_eager                         False
gpu_memory_utilization                0.45
eval_steps                            -1
save_steps                            -1
save_interval                         50
actor_learning_rate                   1e-06
critic_learning_rate                  5e-06
num_episodes                          20
max_epochs                            1
prompt_max_len                        2048
generate_max_len                      8000
train_batch_size                      256
micro_train_batch_size                1
rollout_batch_size                    128
micro_rollout_batch_size              128
micro_forward_batch_size              1
policy_update_steps                   1
critic_update_steps                   12
max_len                               8192
max_norm                              1.0
num_warmup_steps                      50
l2                                    0.0
eps_clip                              0.2
value_clip                            0.2
lambd                                 1.0
gamma                                 1.0
normalize_reward                      True
top_p                                 1.0
temperature                           1.0
freezing_actor_steps                  -1
n_samples_per_prompt                  64
kl_target                             <class 'NoneType'>
init_kl_coef                          0
use_kl_estimator_k3                   True
use_abs_kl                            False
use_kl_loss                           True
kl_loss_coef                          0.0
adam_betas                            (0.9, 0.95)
reward_clip_range                     (-10, 10)
use_compute_reward_fn                 True
advantage_normalize                   True
value_head_prefix                     value_head
ref_reward_offload                    False
enable_eval                           True
eval_interval                         10
update_ref_every_epoch                True
use_orm_score                         False
total_num_nodes                       8
exp_name                              orz_0p5b_ppo_8gpu_v2
eval_prompt_data                      <class 'omegaconf.listconfig.ListConfig'>
prompt_data_probs                     <class 'omegaconf.listconfig.ListConfig'>
packing_max_len                       10048
top_k                                 -1
stop                                  <class 'omegaconf.listconfig.ListConfig'>
use_grpo                              False
wandb: Currently logged in as: avecplezir (irina-rish). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.21.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in orz_logs/orz_0p5b_ppo/wandb/run-20250714_155458-wrzopn3r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run orz_0p5b_ppo_8gpu_v2
wandb: ⭐️ View project at https://wandb.ai/irina-rish/open-reasoner-zero
wandb: 🚀 View run at https://wandb.ai/irina-rish/open-reasoner-zero/runs/wrzopn3r
2025-07-14 15:54:59,242	INFO worker.py:1654 -- Connecting to existing Ray cluster at address: 10.224.3.42:36816...
2025-07-14 15:54:59,254	INFO worker.py:1841 -- Connected to Ray cluster.
[36m(LLMActor pid=3700667)[0m INFO 07-14 15:55:06 __init__.py:207] Automatically detected platform cuda.
[36m(LLMActor pid=3700666)[0m INFO 07-14 15:55:18 config.py:549] This model supports multiple tasks: {'classify', 'embed', 'reward', 'generate', 'score'}. Defaulting to 'generate'.
[36m(LLMActor pid=1559111, ip=10.224.3.43)[0m INFO 07-14 15:55:07 __init__.py:207] Automatically detected platform cuda.[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(LLMActor pid=3700666)[0m WARNING 07-14 15:55:18 cuda.py:95] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(LLMActor pid=3700666)[0m WARNING 07-14 15:55:18 config.py:685] Async output processing is not supported on the current platform type cuda.
[36m(LLMActor pid=3700666)[0m INFO 07-14 15:55:18 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/home/a/anokhin/links/scratch/Qwen2.5-0.5B', speculative_config=None, tokenizer='/home/a/anokhin/links/scratch/Qwen2.5-0.5B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=42, served_model_name=/home/a/anokhin/links/scratch/Qwen2.5-0.5B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}, use_cached_outputs=False, 
[36m(LLMActor pid=3700667)[0m INFO 07-14 15:55:18 config.py:549] This model supports multiple tasks: {'generate', 'score', 'classify', 'embed', 'reward'}. Defaulting to 'generate'.
[36m(LLMActor pid=3700667)[0m INFO 07-14 15:55:19 cuda.py:229] Using Flash Attention backend.
[36m(LLMActor pid=3700668)[0m INFO 07-14 15:55:19 config.py:549] This model supports multiple tasks: {'score', 'embed', 'classify', 'generate', 'reward'}. Defaulting to 'generate'.
[36m(LLMActor pid=3700665)[0m INFO 07-14 15:55:19 config.py:549] This model supports multiple tasks: {'classify', 'reward', 'generate', 'score', 'embed'}. Defaulting to 'generate'.
[36m(LLMActor pid=1559114, ip=10.224.3.43)[0m INFO 07-14 15:55:20 config.py:549] This model supports multiple tasks: {'generate', 'embed', 'reward', 'classify', 'score'}. Defaulting to 'generate'.
[36m(LLMActor pid=1559111, ip=10.224.3.43)[0m INFO 07-14 15:55:20 config.py:549] This model supports multiple tasks: {'embed', 'reward', 'classify', 'score', 'generate'}. Defaulting to 'generate'.
[36m(LLMActor pid=3700667)[0m INFO 07-14 15:55:20 model_runner.py:1110] Starting to load model /home/a/anokhin/links/scratch/Qwen2.5-0.5B...
[36m(LLMActor pid=3700666)[0m Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
[36m(LLMActor pid=3700666)[0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.83it/s]
[36m(LLMActor pid=3700666)[0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.83it/s]
[36m(LLMActor pid=3700666)[0m 
[36m(LLMActor pid=3700666)[0m INFO 07-14 15:55:21 model_runner.py:1115] Loading model weights took 0.9277 GB
[36m(LLMActor pid=1559112, ip=10.224.3.43)[0m INFO 07-14 15:55:21 config.py:549] This model supports multiple tasks: {'reward', 'classify', 'embed', 'score', 'generate'}. Defaulting to 'generate'.
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m INFO 07-14 15:55:21 config.py:549] This model supports multiple tasks: {'classify', 'generate', 'score', 'embed', 'reward'}. Defaulting to 'generate'.
[36m(LLMActor pid=3700667)[0m 
[36m(LLMActor pid=3700665)[0m 
[36m(LLMActor pid=3700668)[0m 
[36m(LLMActor pid=3700666)[0m INFO 07-14 15:55:21 worker.py:267] Memory profiling takes 0.37 seconds
[36m(LLMActor pid=3700666)[0m INFO 07-14 15:55:21 worker.py:267] the current vLLM instance can use total_gpu_memory (79.19GiB) x gpu_memory_utilization (0.45) = 35.64GiB
[36m(LLMActor pid=3700666)[0m INFO 07-14 15:55:21 worker.py:267] model weights take 0.93GiB; non_torch_memory takes 0.16GiB; PyTorch activation peak memory takes 0.73GiB; the rest of the memory reserved for KV Cache is 33.82GiB.
[36m(LLMActor pid=3700666)[0m INFO 07-14 15:55:22 executor_base.py:111] # cuda blocks: 11543, # CPU blocks: 1365
[36m(LLMActor pid=3700666)[0m INFO 07-14 15:55:22 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 360.72x
[36m(LLMActor pid=1559111, ip=10.224.3.43)[0m 
[36m(LLMActor pid=1559114, ip=10.224.3.43)[0m 
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m WARNING 07-14 15:55:21 cuda.py:95] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used[32m [repeated 7x across cluster][0m
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m WARNING 07-14 15:55:21 config.py:685] Async output processing is not supported on the current platform type cuda.[32m [repeated 7x across cluster][0m
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m INFO 07-14 15:55:21 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/home/a/anokhin/links/scratch/Qwen2.5-0.5B', speculative_config=None, tokenizer='/home/a/anokhin/links/scratch/Qwen2.5-0.5B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=49, served_model_name=/home/a/anokhin/links/scratch/Qwen2.5-0.5B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[],"max_capture_size":0}, use_cached_outputs=False, [32m [repeated 7x across cluster][0m
[36m(LLMActor pid=1559112, ip=10.224.3.43)[0m 
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m 
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m INFO 07-14 15:55:22 cuda.py:229] Using Flash Attention backend.[32m [repeated 7x across cluster][0m
[36m(LLMActor pid=3700666)[0m INFO 07-14 15:55:24 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 3.01 seconds
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m INFO 07-14 15:55:22 model_runner.py:1110] Starting to load model /home/a/anokhin/links/scratch/Qwen2.5-0.5B...[32m [repeated 7x across cluster][0m
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m INFO 07-14 15:55:23 model_runner.py:1115] Loading model weights took 0.9277 GB[32m [repeated 7x across cluster][0m
2025-07-14 15:55:27.185 | INFO     | orz.ppo.utils:create_vllm_engines:452 - Offloaded all vLLM engines to CPU
2025-07-14 15:55:27.811 | INFO     | playground.orz_7b_ppo:train_dataset:523 - Start processing 56878 dialogues
2025-07-14 15:56:03.314 | INFO     | playground.orz_7b_ppo:train_dataset:532 - Finished processing 56878 dialogues
2025-07-14 15:56:03.335 | INFO     | playground.orz_7b_ppo:eval_dataset:546 - Start processing 728 dialogues
2025-07-14 15:56:03.810 | INFO     | playground.orz_7b_ppo:eval_dataset:555 - Finished processing 728 dialogues
[36m(pid=3701267)[0m [2025-07-14 15:56:06,275] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m INFO 07-14 15:55:24 worker.py:267] Memory profiling takes 0.35 seconds[32m [repeated 7x across cluster][0m
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m INFO 07-14 15:55:24 worker.py:267] the current vLLM instance can use total_gpu_memory (79.19GiB) x gpu_memory_utilization (0.45) = 35.64GiB[32m [repeated 7x across cluster][0m
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m INFO 07-14 15:55:24 worker.py:267] model weights take 0.93GiB; non_torch_memory takes 0.16GiB; PyTorch activation peak memory takes 0.73GiB; the rest of the memory reserved for KV Cache is 33.82GiB.[32m [repeated 7x across cluster][0m
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m INFO 07-14 15:55:24 executor_base.py:111] # cuda blocks: 11543, # CPU blocks: 1365[32m [repeated 7x across cluster][0m
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m INFO 07-14 15:55:24 executor_base.py:116] Maximum concurrency for 8192 tokens per request: 360.72x[32m [repeated 7x across cluster][0m
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m INFO 07-14 15:55:26 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 3.05 seconds[32m [repeated 7x across cluster][0m
[36m(pid=1559636, ip=10.224.3.43)[0m [2025-07-14 15:56:12,433] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(pid=3701438)[0m [2025-07-14 15:56:12,603] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(pid=1560308, ip=10.224.3.43)[0m [2025-07-14 15:56:19,411] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)[32m [repeated 7x across cluster][0m
[36m(RefRayActorBase pid=1560293, ip=10.224.3.43)[0m [2025-07-14 15:56:24,004] [INFO] [comm.py:652:init_distributed] cdb=None
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:56:24,076] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[36m(RefRayActorBase pid=1560306, ip=10.224.3.43)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s][32m [repeated 7x across cluster][0m
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.55it/s][32m [repeated 14x across cluster][0m
[36m(RefRayActorBase pid=1560306, ip=10.224.3.43)[0m [2025-07-14 15:56:24,157] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[36m(pid=3702112)[0m [2025-07-14 15:56:20,445] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)[32m [repeated 7x across cluster][0m
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:56:39,210] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 291, num_elems = 0.63B
[36m(RefRayActorBase pid=3702112)[0m [2025-07-14 15:56:24,286] [INFO] [comm.py:652:init_distributed] cdb=None[32m [repeated 7x across cluster][0m
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:56:24,825] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8[32m [repeated 7x across cluster][0m
[36m(pid=1560956, ip=10.224.3.43)[0m [2025-07-14 15:56:28,711] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)[32m [repeated 7x across cluster][0m
[36m(RefRayActorBase pid=1560293, ip=10.224.3.43)[0m [2025-07-14 15:57:01,349] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[36m(RefRayActorBase pid=1560307, ip=10.224.3.43)[0m [2025-07-14 15:57:01,349] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,386] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.0, git-hash=unknown, git-branch=unknown
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,386] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,394] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,396] [INFO] [logging.py:128:log_dist] [Rank 0] Creating ZeRO Offload
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,585] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,585] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.62 GB         CA 0.81 GB         Max_CA 1 GB 
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,586] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 56.12 GB, percent = 11.1%
[36m(RefRayActorBase pid=3701439)[0m Parameter Offload: Total persistent parameters: 71552 in 121 params
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,702] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,703] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.12 GB         CA 0.81 GB         Max_CA 1 GB 
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,703] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 56.12 GB, percent = 11.1%
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,704] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,704] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
[36m(RefRayActorBase pid=3701439)[0m     "partition_activations": false, 
[36m(RefRayActorBase pid=3701439)[0m     "contiguous_memory_optimization": false, 
[36m(RefRayActorBase pid=3701439)[0m     "cpu_checkpointing": false, 
[36m(RefRayActorBase pid=3701439)[0m     "number_checkpoints": null, 
[36m(RefRayActorBase pid=3701439)[0m     "synchronize_checkpoint_boundary": false, 
[36m(RefRayActorBase pid=3701439)[0m     "profile": false
[36m(RefRayActorBase pid=3701439)[0m }
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,704] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   amp_enabled .................. False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   amp_params ................... False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   autotuning_config ............ {
[36m(RefRayActorBase pid=3701439)[0m     "enabled": false, 
[36m(RefRayActorBase pid=3701439)[0m     "start_step": null, 
[36m(RefRayActorBase pid=3701439)[0m     "end_step": null, 
[36m(RefRayActorBase pid=3701439)[0m     "metric_path": null, 
[36m(RefRayActorBase pid=3701439)[0m     "arg_mappings": null, 
[36m(RefRayActorBase pid=3701439)[0m     "metric": "throughput", 
[36m(RefRayActorBase pid=3701439)[0m     "model_info": null, 
[36m(RefRayActorBase pid=3701439)[0m     "results_dir": "autotuning_results", 
[36m(RefRayActorBase pid=3701439)[0m     "exps_dir": "autotuning_exps", 
[36m(RefRayActorBase pid=3701439)[0m     "overwrite": true, 
[36m(RefRayActorBase pid=3701439)[0m     "fast": true, 
[36m(RefRayActorBase pid=3701439)[0m     "start_profile_step": 3, 
[36m(RefRayActorBase pid=3701439)[0m     "end_profile_step": 5, 
[36m(RefRayActorBase pid=3701439)[0m     "tuner_type": "gridsearch", 
[36m(RefRayActorBase pid=3701439)[0m     "tuner_early_stopping": 5, 
[36m(RefRayActorBase pid=3701439)[0m     "tuner_num_trials": 50, 
[36m(RefRayActorBase pid=3701439)[0m     "model_info_path": null, 
[36m(RefRayActorBase pid=3701439)[0m     "mp_size": 1, 
[36m(RefRayActorBase pid=3701439)[0m     "max_train_batch_size": null, 
[36m(RefRayActorBase pid=3701439)[0m     "min_train_batch_size": 1, 
[36m(RefRayActorBase pid=3701439)[0m     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[36m(RefRayActorBase pid=3701439)[0m     "min_train_micro_batch_size_per_gpu": 1, 
[36m(RefRayActorBase pid=3701439)[0m     "num_tuning_micro_batch_sizes": 3
[36m(RefRayActorBase pid=3701439)[0m }
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x740719b562a0>
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   communication_data_type ...... None
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   disable_allgather ............ False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   dump_state ................... False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
[36m(RefRayActorBase pid=3701439)[0m     "enabled": false, 
[36m(RefRayActorBase pid=3701439)[0m     "recompute_fwd_factor": 0.0, 
[36m(RefRayActorBase pid=3701439)[0m     "profile_step": 1, 
[36m(RefRayActorBase pid=3701439)[0m     "module_depth": -1, 
[36m(RefRayActorBase pid=3701439)[0m     "top_modules": 1, 
[36m(RefRayActorBase pid=3701439)[0m     "detailed": true, 
[36m(RefRayActorBase pid=3701439)[0m     "output_file": null
[36m(RefRayActorBase pid=3701439)[0m }
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   global_rank .................. 0
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 1
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,705] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   nebula_config ................ {
[36m(RefRayActorBase pid=3701439)[0m     "enabled": false, 
[36m(RefRayActorBase pid=3701439)[0m     "persistent_storage_path": null, 
[36m(RefRayActorBase pid=3701439)[0m     "persistent_time_interval": 100, 
[36m(RefRayActorBase pid=3701439)[0m     "num_of_version_in_retention": 2, 
[36m(RefRayActorBase pid=3701439)[0m     "enable_nebula_load": true, 
[36m(RefRayActorBase pid=3701439)[0m     "load_path": null
[36m(RefRayActorBase pid=3701439)[0m }
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   optimizer_name ............... None
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   optimizer_params ............. None
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   pld_enabled .................. False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   pld_params ................... False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   scheduler_name ............... None
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   scheduler_params ............. None
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   sparse_attention ............. None
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   steps_per_print .............. 100
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   train_batch_size ............. 8
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  1
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   world_size ................... 8
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=True) offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   zero_enabled ................. True
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 3
[36m(RefRayActorBase pid=3701439)[0m [2025-07-14 15:57:01,706] [INFO] [config.py:989:print_user_config]   json = {
[36m(RefRayActorBase pid=3701439)[0m     "steps_per_print": 100, 
[36m(RefRayActorBase pid=3701439)[0m     "zero_optimization": {
[36m(RefRayActorBase pid=3701439)[0m         "stage": 3, 
[36m(RefRayActorBase pid=3701439)[0m         "stage3_param_persistence_threshold": "auto", 
[36m(RefRayActorBase pid=3701439)[0m         "offload_param": {
[36m(RefRayActorBase pid=3701439)[0m             "device": "cpu", 
[36m(RefRayActorBase pid=3701439)[0m             "pin_memory": true
[36m(RefRayActorBase pid=3701439)[0m         }
[36m(RefRayActorBase pid=3701439)[0m     }, 
[36m(RefRayActorBase pid=3701439)[0m     "bf16": {
[36m(RefRayActorBase pid=3701439)[0m         "enabled": true
[36m(RefRayActorBase pid=3701439)[0m     }, 
[36m(RefRayActorBase pid=3701439)[0m     "gradient_clipping": 1.0, 
[36m(RefRayActorBase pid=3701439)[0m     "prescale_gradients": false, 
[36m(RefRayActorBase pid=3701439)[0m     "wall_clock_breakdown": false, 
[36m(RefRayActorBase pid=3701439)[0m     "train_micro_batch_size_per_gpu": 1, 
[36m(RefRayActorBase pid=3701439)[0m     "gradient_accumulation_steps": 1
[36m(RefRayActorBase pid=3701439)[0m }
[36m(PolicyRayActorBase pid=3701441)[0m [2025-07-14 15:57:01,981] [INFO] [comm.py:652:init_distributed] cdb=None
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:02,059] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[36m(PolicyRayActorBase pid=3701441)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 8x across cluster][0m
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:15,714] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 291, num_elems = 0.63B
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:02,786] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8[32m [repeated 14x across cluster][0m
[36m(PolicyRayActorBase pid=3701440)[0m [2025-07-14 15:57:02,023] [INFO] [comm.py:652:init_distributed] cdb=None[32m [repeated 7x across cluster][0m
[36m(PolicyRayActorBase pid=1559636, ip=10.224.3.43)[0m Using /home/a/anokhin/.cache/torch_extensions/py312_cu122 as PyTorch extensions root...
[36m(PolicyRayActorBase pid=3701267)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 7x across cluster][0m
[36m(PolicyRayActorBase pid=1559633, ip=10.224.3.43)[0m Detected CUDA files, patching ldflags
[36m(PolicyRayActorBase pid=1559633, ip=10.224.3.43)[0m Emitting ninja build file /home/a/anokhin/.cache/torch_extensions/py312_cu122/fused_adam/build.ninja...
[36m(PolicyRayActorBase pid=1559633, ip=10.224.3.43)[0m /home/a/anokhin/envs/reasoner3.12/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[36m(PolicyRayActorBase pid=1559633, ip=10.224.3.43)[0m If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
[36m(PolicyRayActorBase pid=1559633, ip=10.224.3.43)[0m   warnings.warn(
[36m(PolicyRayActorBase pid=1559633, ip=10.224.3.43)[0m Building extension module fused_adam...
[36m(PolicyRayActorBase pid=1559633, ip=10.224.3.43)[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[36m(PolicyRayActorBase pid=1559633, ip=10.224.3.43)[0m ninja: no work to do.
[36m(PolicyRayActorBase pid=1559633, ip=10.224.3.43)[0m Time to load fused_adam op: 0.27489709854125977 seconds
[36m(PolicyRayActorBase pid=1559633, ip=10.224.3.43)[0m [2025-07-14 15:57:38,163] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[36m(PolicyRayActorBase pid=1559635, ip=10.224.3.43)[0m [2025-07-14 15:57:38,194] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[36m(PolicyRayActorBase pid=1559636, ip=10.224.3.43)[0m Loading extension module fused_adam...
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,231] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.0, git-hash=unknown, git-branch=unknown
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,231] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,241] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,241] [INFO] [logging.py:128:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,242] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,250] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,250] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,250] [INFO] [logging.py:128:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,250] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,496] [INFO] [utils.py:781:see_memory_usage] Stage 3 initialize beginning
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,496] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.62 GB         CA 0.81 GB         Max_CA 1 GB 
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,496] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 58.39 GB, percent = 11.6%
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,497] [INFO] [stage3.py:167:__init__] Reduce bucket size 500000000
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,497] [INFO] [stage3.py:168:__init__] Prefetch bucket size 50000000
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,597] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,597] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.12 GB         CA 0.81 GB         Max_CA 1 GB 
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,597] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 58.39 GB, percent = 11.6%
[36m(PolicyRayActorBase pid=3701267)[0m Parameter Offload: Total persistent parameters: 71552 in 121 params
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,709] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,709] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.12 GB         CA 0.81 GB         Max_CA 1 GB 
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,709] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 58.4 GB, percent = 11.6%
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,813] [INFO] [utils.py:781:see_memory_usage] Before creating fp16 partitions
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,813] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.12 GB         CA 0.81 GB         Max_CA 1 GB 
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:38,814] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 58.4 GB, percent = 11.6%
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:39,162] [INFO] [utils.py:781:see_memory_usage] After creating fp16 partitions: 2
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:39,162] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.12 GB         CA 0.12 GB         Max_CA 1 GB 
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:39,162] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 58.87 GB, percent = 11.7%
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:39,270] [INFO] [utils.py:781:see_memory_usage] Before creating fp32 partitions
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:39,271] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.12 GB         CA 0.12 GB         Max_CA 0 GB 
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:39,271] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 58.86 GB, percent = 11.7%
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:39,373] [INFO] [utils.py:781:see_memory_usage] After creating fp32 partitions
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:39,373] [INFO] [utils.py:782:see_memory_usage] MA 0.35 GB         Max_MA 0.46 GB         CA 0.46 GB         Max_CA 0 GB 
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:39,374] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 58.85 GB, percent = 11.7%
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:39,475] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:39,476] [INFO] [utils.py:782:see_memory_usage] MA 0.35 GB         Max_MA 0.35 GB         CA 0.46 GB         Max_CA 0 GB 
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:39,476] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 58.85 GB, percent = 11.7%
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:39,578] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:39,578] [INFO] [utils.py:782:see_memory_usage] MA 0.35 GB         Max_MA 0.58 GB         CA 0.69 GB         Max_CA 1 GB 
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:39,578] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 58.85 GB, percent = 11.7%
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:39,579] [INFO] [stage3.py:525:_setup_for_real_optimizer] optimizer state initialized
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,922] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,923] [INFO] [utils.py:782:see_memory_usage] MA 1.51 GB         Max_MA 2.02 GB         CA 2.13 GB         Max_CA 2 GB 
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,923] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 58.59 GB, percent = 11.6%
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,923] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer_Stage3
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,923] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,923] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x71cfec278a10>
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,923] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,924] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,924] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
[36m(PolicyRayActorBase pid=3701267)[0m     "partition_activations": false, 
[36m(PolicyRayActorBase pid=3701267)[0m     "contiguous_memory_optimization": false, 
[36m(PolicyRayActorBase pid=3701267)[0m     "cpu_checkpointing": false, 
[36m(PolicyRayActorBase pid=3701267)[0m     "number_checkpoints": null, 
[36m(PolicyRayActorBase pid=3701267)[0m     "synchronize_checkpoint_boundary": false, 
[36m(PolicyRayActorBase pid=3701267)[0m     "profile": false
[36m(PolicyRayActorBase pid=3701267)[0m }
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,924] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,924] [INFO] [config.py:1003:print]   amp_enabled .................. False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,924] [INFO] [config.py:1003:print]   amp_params ................... False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,924] [INFO] [config.py:1003:print]   autotuning_config ............ {
[36m(PolicyRayActorBase pid=3701267)[0m     "enabled": false, 
[36m(PolicyRayActorBase pid=3701267)[0m     "start_step": null, 
[36m(PolicyRayActorBase pid=3701267)[0m     "end_step": null, 
[36m(PolicyRayActorBase pid=3701267)[0m     "metric_path": null, 
[36m(PolicyRayActorBase pid=3701267)[0m     "arg_mappings": null, 
[36m(PolicyRayActorBase pid=3701267)[0m     "metric": "throughput", 
[36m(PolicyRayActorBase pid=3701267)[0m     "model_info": null, 
[36m(PolicyRayActorBase pid=3701267)[0m     "results_dir": "autotuning_results", 
[36m(PolicyRayActorBase pid=3701267)[0m     "exps_dir": "autotuning_exps", 
[36m(PolicyRayActorBase pid=3701267)[0m     "overwrite": true, 
[36m(PolicyRayActorBase pid=3701267)[0m     "fast": true, 
[36m(PolicyRayActorBase pid=3701267)[0m     "start_profile_step": 3, 
[36m(PolicyRayActorBase pid=3701267)[0m     "end_profile_step": 5, 
[36m(PolicyRayActorBase pid=3701267)[0m     "tuner_type": "gridsearch", 
[36m(PolicyRayActorBase pid=3701267)[0m     "tuner_early_stopping": 5, 
[36m(PolicyRayActorBase pid=3701267)[0m     "tuner_num_trials": 50, 
[36m(PolicyRayActorBase pid=3701267)[0m     "model_info_path": null, 
[36m(PolicyRayActorBase pid=3701267)[0m     "mp_size": 1, 
[36m(PolicyRayActorBase pid=3701267)[0m     "max_train_batch_size": null, 
[36m(PolicyRayActorBase pid=3701267)[0m     "min_train_batch_size": 1, 
[36m(PolicyRayActorBase pid=3701267)[0m     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[36m(PolicyRayActorBase pid=3701267)[0m     "min_train_micro_batch_size_per_gpu": 1, 
[36m(PolicyRayActorBase pid=3701267)[0m     "num_tuning_micro_batch_sizes": 3
[36m(PolicyRayActorBase pid=3701267)[0m }
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,924] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,924] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,924] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,924] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,924] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,924] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x71cfec23b2c0>
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,924] [INFO] [config.py:1003:print]   communication_data_type ...... None
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   disable_allgather ............ False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   dump_state ................... False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
[36m(PolicyRayActorBase pid=3701267)[0m     "enabled": false, 
[36m(PolicyRayActorBase pid=3701267)[0m     "recompute_fwd_factor": 0.0, 
[36m(PolicyRayActorBase pid=3701267)[0m     "profile_step": 1, 
[36m(PolicyRayActorBase pid=3701267)[0m     "module_depth": -1, 
[36m(PolicyRayActorBase pid=3701267)[0m     "top_modules": 1, 
[36m(PolicyRayActorBase pid=3701267)[0m     "detailed": true, 
[36m(PolicyRayActorBase pid=3701267)[0m     "output_file": null
[36m(PolicyRayActorBase pid=3701267)[0m }
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   global_rank .................. 0
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   grad_accum_dtype ............. fp32
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 1
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   nebula_config ................ {
[36m(PolicyRayActorBase pid=3701267)[0m     "enabled": false, 
[36m(PolicyRayActorBase pid=3701267)[0m     "persistent_storage_path": null, 
[36m(PolicyRayActorBase pid=3701267)[0m     "persistent_time_interval": 100, 
[36m(PolicyRayActorBase pid=3701267)[0m     "num_of_version_in_retention": 2, 
[36m(PolicyRayActorBase pid=3701267)[0m     "enable_nebula_load": true, 
[36m(PolicyRayActorBase pid=3701267)[0m     "load_path": null
[36m(PolicyRayActorBase pid=3701267)[0m }
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   optimizer_name ............... None
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   optimizer_params ............. None
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   pld_enabled .................. False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   pld_params ................... False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   scheduler_name ............... None
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   scheduler_params ............. None
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   sparse_attention ............. None
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   steps_per_print .............. 100
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   train_batch_size ............. 8
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  1
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   world_size ................... 8
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=True, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   zero_enabled ................. True
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,925] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 3
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 15:57:47,926] [INFO] [config.py:989:print_user_config]   json = {
[36m(PolicyRayActorBase pid=3701267)[0m     "steps_per_print": 100, 
[36m(PolicyRayActorBase pid=3701267)[0m     "zero_optimization": {
[36m(PolicyRayActorBase pid=3701267)[0m         "stage": 3, 
[36m(PolicyRayActorBase pid=3701267)[0m         "offload_param": {
[36m(PolicyRayActorBase pid=3701267)[0m             "device": "none"
[36m(PolicyRayActorBase pid=3701267)[0m         }, 
[36m(PolicyRayActorBase pid=3701267)[0m         "offload_optimizer": {
[36m(PolicyRayActorBase pid=3701267)[0m             "device": "none", 
[36m(PolicyRayActorBase pid=3701267)[0m             "pin_memory": true
[36m(PolicyRayActorBase pid=3701267)[0m         }, 
[36m(PolicyRayActorBase pid=3701267)[0m         "sub_group_size": "auto", 
[36m(PolicyRayActorBase pid=3701267)[0m         "stage3_max_live_parameters": "auto", 
[36m(PolicyRayActorBase pid=3701267)[0m         "stage3_max_reuse_distance": "auto", 
[36m(PolicyRayActorBase pid=3701267)[0m         "stage3_param_persistence_threshold": "auto", 
[36m(PolicyRayActorBase pid=3701267)[0m         "stage3_prefetch_bucket_size": "auto", 
[36m(PolicyRayActorBase pid=3701267)[0m         "reduce_bucket_size": "auto", 
[36m(PolicyRayActorBase pid=3701267)[0m         "zero_hpz_partition_size": 1, 
[36m(PolicyRayActorBase pid=3701267)[0m         "zero_quantized_weights": false, 
[36m(PolicyRayActorBase pid=3701267)[0m         "zero_quantized_gradients": false
[36m(PolicyRayActorBase pid=3701267)[0m     }, 
[36m(PolicyRayActorBase pid=3701267)[0m     "bf16": {
[36m(PolicyRayActorBase pid=3701267)[0m         "enabled": true
[36m(PolicyRayActorBase pid=3701267)[0m     }, 
[36m(PolicyRayActorBase pid=3701267)[0m     "gradient_clipping": 1.0, 
[36m(PolicyRayActorBase pid=3701267)[0m     "prescale_gradients": false, 
[36m(PolicyRayActorBase pid=3701267)[0m     "wall_clock_breakdown": false, 
[36m(PolicyRayActorBase pid=3701267)[0m     "data_types": {
[36m(PolicyRayActorBase pid=3701267)[0m         "grad_accum_dtype": "fp32"
[36m(PolicyRayActorBase pid=3701267)[0m     }, 
[36m(PolicyRayActorBase pid=3701267)[0m     "train_micro_batch_size_per_gpu": 1, 
[36m(PolicyRayActorBase pid=3701267)[0m     "gradient_accumulation_steps": 1
[36m(PolicyRayActorBase pid=3701267)[0m }
[36m(PolicyRayActorBase pid=3701441)[0m Time to load fused_adam op: 0.3070967197418213 seconds[32m [repeated 7x across cluster][0m
[36m(PolicyRayActorBase pid=3701441)[0m [2025-07-14 15:57:38,196] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8[32m [repeated 6x across cluster][0m
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:57:48,741] [INFO] [comm.py:652:init_distributed] cdb=None
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:57:48,741] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[36m(CriticRayActorBase pid=1560953, ip=10.224.3.43)[0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
[36m(PolicyRayActorBase pid=3701441)[0m Using /home/a/anokhin/.cache/torch_extensions/py312_cu122 as PyTorch extensions root...[32m [repeated 7x across cluster][0m
[36m(CriticRayActorBase pid=1560953, ip=10.224.3.43)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(PolicyRayActorBase pid=3701441)[0m Loading extension module fused_adam...[32m [repeated 7x across cluster][0m
[36m(CriticRayActorBase pid=1560954, ip=10.224.3.43)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:00,515] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 291, num_elems = 0.49B
[36m(CriticRayActorBase pid=3702760)[0m [2025-07-14 15:57:49,599] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8[32m [repeated 8x across cluster][0m
[36m(CriticRayActorBase pid=1560955, ip=10.224.3.43)[0m [2025-07-14 15:57:48,731] [INFO] [comm.py:652:init_distributed] cdb=None[32m [repeated 7x across cluster][0m
[36m(CriticRayActorBase pid=3702113)[0m Some weights of CriticModel were not initialized from the model checkpoint at /home/a/anokhin/links/scratch/Qwen2.5-0.5B and are newly initialized: ['value_head.weight']
[36m(CriticRayActorBase pid=3702113)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(CriticRayActorBase pid=3702760)[0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.[32m [repeated 7x across cluster][0m
[36m(CriticRayActorBase pid=3702760)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 6x across cluster][0m
[36m(CriticRayActorBase pid=3702761)[0m 2025-07-14 15:58:18.230 | INFO     | orz.ppo.models:get_llm_for_sequence_regression:572 - initialize value_head for ZeRO-3 reward model training.
[36m(CriticRayActorBase pid=1560953, ip=10.224.3.43)[0m Using /home/a/anokhin/.cache/torch_extensions/py312_cu122 as PyTorch extensions root...
[36m(CriticRayActorBase pid=1560955, ip=10.224.3.43)[0m Detected CUDA files, patching ldflags
[36m(CriticRayActorBase pid=1560955, ip=10.224.3.43)[0m Emitting ninja build file /home/a/anokhin/.cache/torch_extensions/py312_cu122/fused_adam/build.ninja...
[36m(CriticRayActorBase pid=1560955, ip=10.224.3.43)[0m /home/a/anokhin/envs/reasoner3.12/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[36m(CriticRayActorBase pid=1560955, ip=10.224.3.43)[0m If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
[36m(CriticRayActorBase pid=1560955, ip=10.224.3.43)[0m   warnings.warn(
[36m(CriticRayActorBase pid=1560955, ip=10.224.3.43)[0m Building extension module fused_adam...
[36m(CriticRayActorBase pid=1560955, ip=10.224.3.43)[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[36m(CriticRayActorBase pid=3702113)[0m Time to load fused_adam op: 0.20531296730041504 seconds
[36m(CriticRayActorBase pid=3702113)[0m Loading extension module fused_adam...
[36m(CriticRayActorBase pid=3702761)[0m [2025-07-14 15:58:18,477] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,477] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.0, git-hash=unknown, git-branch=unknown
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,477] [INFO] [comm.py:677:init_distributed] Distributed backend already initialized
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,485] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,485] [INFO] [logging.py:128:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,485] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,492] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,492] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,492] [INFO] [logging.py:128:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,492] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[36m(CriticRayActorBase pid=1560955, ip=10.224.3.43)[0m ninja: no work to do.
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,683] [INFO] [utils.py:781:see_memory_usage] Stage 3 initialize beginning
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,684] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.62 GB         CA 0.81 GB         Max_CA 1 GB 
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,684] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 61.79 GB, percent = 12.3%
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,685] [INFO] [stage3.py:167:__init__] Reduce bucket size 500000000
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,685] [INFO] [stage3.py:168:__init__] Prefetch bucket size 50000000
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,789] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,789] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.12 GB         CA 0.81 GB         Max_CA 1 GB 
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,789] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 61.79 GB, percent = 12.3%
[36m(CriticRayActorBase pid=3702113)[0m Parameter Offload: Total persistent parameters: 72448 in 122 params
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,904] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,905] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.12 GB         CA 0.81 GB         Max_CA 1 GB 
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:18,905] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 61.79 GB, percent = 12.3%
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,009] [INFO] [utils.py:781:see_memory_usage] Before creating fp16 partitions
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,009] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.12 GB         CA 0.81 GB         Max_CA 1 GB 
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,009] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 61.79 GB, percent = 12.3%
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,342] [INFO] [utils.py:781:see_memory_usage] After creating fp16 partitions: 2
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,343] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.12 GB         CA 0.12 GB         Max_CA 1 GB 
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,343] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 62.25 GB, percent = 12.4%
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,458] [INFO] [utils.py:781:see_memory_usage] Before creating fp32 partitions
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,459] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.12 GB         CA 0.12 GB         Max_CA 0 GB 
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,459] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 62.25 GB, percent = 12.4%
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,563] [INFO] [utils.py:781:see_memory_usage] After creating fp32 partitions
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,564] [INFO] [utils.py:782:see_memory_usage] MA 0.35 GB         Max_MA 0.46 GB         CA 0.46 GB         Max_CA 0 GB 
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,564] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 62.25 GB, percent = 12.4%
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,669] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,669] [INFO] [utils.py:782:see_memory_usage] MA 0.35 GB         Max_MA 0.35 GB         CA 0.46 GB         Max_CA 0 GB 
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,669] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 62.25 GB, percent = 12.4%
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,775] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,775] [INFO] [utils.py:782:see_memory_usage] MA 0.35 GB         Max_MA 0.58 GB         CA 0.7 GB         Max_CA 1 GB 
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,775] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 62.25 GB, percent = 12.4%
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:19,776] [INFO] [stage3.py:525:_setup_for_real_optimizer] optimizer state initialized
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,118] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,118] [INFO] [utils.py:782:see_memory_usage] MA 1.51 GB         Max_MA 2.02 GB         CA 2.13 GB         Max_CA 2 GB 
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,118] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 62.05 GB, percent = 12.3%
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,119] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer_Stage3
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,119] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,119] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7c16e0b274d0>
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,119] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,119] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,119] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
[36m(CriticRayActorBase pid=3702113)[0m     "partition_activations": false, 
[36m(CriticRayActorBase pid=3702113)[0m     "contiguous_memory_optimization": false, 
[36m(CriticRayActorBase pid=3702113)[0m     "cpu_checkpointing": false, 
[36m(CriticRayActorBase pid=3702113)[0m     "number_checkpoints": null, 
[36m(CriticRayActorBase pid=3702113)[0m     "synchronize_checkpoint_boundary": false, 
[36m(CriticRayActorBase pid=3702113)[0m     "profile": false
[36m(CriticRayActorBase pid=3702113)[0m }
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   amp_enabled .................. False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   amp_params ................... False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   autotuning_config ............ {
[36m(CriticRayActorBase pid=3702113)[0m     "enabled": false, 
[36m(CriticRayActorBase pid=3702113)[0m     "start_step": null, 
[36m(CriticRayActorBase pid=3702113)[0m     "end_step": null, 
[36m(CriticRayActorBase pid=3702113)[0m     "metric_path": null, 
[36m(CriticRayActorBase pid=3702113)[0m     "arg_mappings": null, 
[36m(CriticRayActorBase pid=3702113)[0m     "metric": "throughput", 
[36m(CriticRayActorBase pid=3702113)[0m     "model_info": null, 
[36m(CriticRayActorBase pid=3702113)[0m     "results_dir": "autotuning_results", 
[36m(CriticRayActorBase pid=3702113)[0m     "exps_dir": "autotuning_exps", 
[36m(CriticRayActorBase pid=3702113)[0m     "overwrite": true, 
[36m(CriticRayActorBase pid=3702113)[0m     "fast": true, 
[36m(CriticRayActorBase pid=3702113)[0m     "start_profile_step": 3, 
[36m(CriticRayActorBase pid=3702113)[0m     "end_profile_step": 5, 
[36m(CriticRayActorBase pid=3702113)[0m     "tuner_type": "gridsearch", 
[36m(CriticRayActorBase pid=3702113)[0m     "tuner_early_stopping": 5, 
[36m(CriticRayActorBase pid=3702113)[0m     "tuner_num_trials": 50, 
[36m(CriticRayActorBase pid=3702113)[0m     "model_info_path": null, 
[36m(CriticRayActorBase pid=3702113)[0m     "mp_size": 1, 
[36m(CriticRayActorBase pid=3702113)[0m     "max_train_batch_size": null, 
[36m(CriticRayActorBase pid=3702113)[0m     "min_train_batch_size": 1, 
[36m(CriticRayActorBase pid=3702113)[0m     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[36m(CriticRayActorBase pid=3702113)[0m     "min_train_micro_batch_size_per_gpu": 1, 
[36m(CriticRayActorBase pid=3702113)[0m     "num_tuning_micro_batch_sizes": 3
[36m(CriticRayActorBase pid=3702113)[0m }
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7c16d5ba9100>
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   communication_data_type ...... None
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   disable_allgather ............ False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   dump_state ................... False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
[36m(CriticRayActorBase pid=3702113)[0m     "enabled": false, 
[36m(CriticRayActorBase pid=3702113)[0m     "recompute_fwd_factor": 0.0, 
[36m(CriticRayActorBase pid=3702113)[0m     "profile_step": 1, 
[36m(CriticRayActorBase pid=3702113)[0m     "module_depth": -1, 
[36m(CriticRayActorBase pid=3702113)[0m     "top_modules": 1, 
[36m(CriticRayActorBase pid=3702113)[0m     "detailed": true, 
[36m(CriticRayActorBase pid=3702113)[0m     "output_file": null
[36m(CriticRayActorBase pid=3702113)[0m }
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   global_rank .................. 0
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   grad_accum_dtype ............. fp32
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 1
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,120] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   nebula_config ................ {
[36m(CriticRayActorBase pid=3702113)[0m     "enabled": false, 
[36m(CriticRayActorBase pid=3702113)[0m     "persistent_storage_path": null, 
[36m(CriticRayActorBase pid=3702113)[0m     "persistent_time_interval": 100, 
[36m(CriticRayActorBase pid=3702113)[0m     "num_of_version_in_retention": 2, 
[36m(CriticRayActorBase pid=3702113)[0m     "enable_nebula_load": true, 
[36m(CriticRayActorBase pid=3702113)[0m     "load_path": null
[36m(CriticRayActorBase pid=3702113)[0m }
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   optimizer_name ............... None
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   optimizer_params ............. None
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   pld_enabled .................. False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   pld_params ................... False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   scheduler_name ............... None
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   scheduler_params ............. None
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   sparse_attention ............. None
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   steps_per_print .............. 100
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   train_batch_size ............. 8
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  1
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   world_size ................... 8
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=True, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   zero_enabled ................. True
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 3
[36m(CriticRayActorBase pid=3702113)[0m [2025-07-14 15:58:28,121] [INFO] [config.py:989:print_user_config]   json = {
[36m(CriticRayActorBase pid=3702113)[0m     "steps_per_print": 100, 
[36m(CriticRayActorBase pid=3702113)[0m     "zero_optimization": {
[36m(CriticRayActorBase pid=3702113)[0m         "stage": 3, 
[36m(CriticRayActorBase pid=3702113)[0m         "offload_param": {
[36m(CriticRayActorBase pid=3702113)[0m             "device": "none"
[36m(CriticRayActorBase pid=3702113)[0m         }, 
[36m(CriticRayActorBase pid=3702113)[0m         "offload_optimizer": {
[36m(CriticRayActorBase pid=3702113)[0m             "device": "none", 
[36m(CriticRayActorBase pid=3702113)[0m             "pin_memory": true
[36m(CriticRayActorBase pid=3702113)[0m         }, 
[36m(CriticRayActorBase pid=3702113)[0m         "sub_group_size": "auto", 
[36m(CriticRayActorBase pid=3702113)[0m         "stage3_max_live_parameters": "auto", 
[36m(CriticRayActorBase pid=3702113)[0m         "stage3_max_reuse_distance": "auto", 
[36m(CriticRayActorBase pid=3702113)[0m         "stage3_param_persistence_threshold": "auto", 
[36m(CriticRayActorBase pid=3702113)[0m         "stage3_prefetch_bucket_size": "auto", 
[36m(CriticRayActorBase pid=3702113)[0m         "reduce_bucket_size": "auto", 
[36m(CriticRayActorBase pid=3702113)[0m         "zero_hpz_partition_size": 1, 
[36m(CriticRayActorBase pid=3702113)[0m         "zero_quantized_weights": false, 
[36m(CriticRayActorBase pid=3702113)[0m         "zero_quantized_gradients": false
[36m(CriticRayActorBase pid=3702113)[0m     }, 
[36m(CriticRayActorBase pid=3702113)[0m     "bf16": {
[36m(CriticRayActorBase pid=3702113)[0m         "enabled": true
[36m(CriticRayActorBase pid=3702113)[0m     }, 
[36m(CriticRayActorBase pid=3702113)[0m     "gradient_clipping": 1.0, 
[36m(CriticRayActorBase pid=3702113)[0m     "prescale_gradients": false, 
[36m(CriticRayActorBase pid=3702113)[0m     "wall_clock_breakdown": false, 
[36m(CriticRayActorBase pid=3702113)[0m     "data_types": {
[36m(CriticRayActorBase pid=3702113)[0m         "grad_accum_dtype": "fp32"
[36m(CriticRayActorBase pid=3702113)[0m     }, 
[36m(CriticRayActorBase pid=3702113)[0m     "train_micro_batch_size_per_gpu": 1, 
[36m(CriticRayActorBase pid=3702113)[0m     "gradient_accumulation_steps": 1
[36m(CriticRayActorBase pid=3702113)[0m }
[36m(CriticRayActorBase pid=1560955, ip=10.224.3.43)[0m Time to load fused_adam op: 0.1772596836090088 seconds[32m [repeated 7x across cluster][0m
[36m(CriticRayActorBase pid=1560955, ip=10.224.3.43)[0m [2025-07-14 15:58:18,449] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 8[32m [repeated 7x across cluster][0m
2025-07-14 15:58:28.613 | INFO     | orz.ppo.trainer:build_models:728 - init policy/ref/critic/reward models done
2025-07-14 15:58:29.749 | INFO     | orz.ppo.trainer:train:73 - Create vllm engine gourps done.
[36m(LLMActor pid=3700667)[0m init_process_group: master_address=10.224.3.42, master_port=39675,  rank=4, world_size=9, group_name=openrlhf
[36m(PolicyRayActorBase pid=3701267)[0m WARNING:using --vllm_sync_backend=gloo for vLLM version > 0.4.2 (or export NCCL_P2P_DISABLE=1)
2025-07-14 15:58:39.458 | INFO     | orz.ppo.trainer:train:75 - Sync actor weights to vllm engines, time cost: 9.71s
[36m(PolicyRayActorBase pid=3701267)[0m Broadcast actor weights to vllm engines done
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m init_process_group: master_address=10.224.3.42, master_port=39675,  rank=8, world_size=9, group_name=openrlhf[32m [repeated 7x across cluster][0m
2025-07-14 15:58:39.699 | INFO     | orz.ppo.trainer:train:79 - Offload policy model to cpu, time cost: 0.24s
Episode [1/20]:   0%|          | 0/445 [00:00<?, ?it/s]2025-07-14 15:58:39.850 | INFO     | playground.orz_7b_ppo:eval:399 - Start evaluating on val set
[36m(LLMActor pid=3700668)[0m Processed prompts:   0%|          | 0/91 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[36m(CriticRayActorBase pid=1560955, ip=10.224.3.43)[0m Some weights of CriticModel were not initialized from the model checkpoint at /home/a/anokhin/links/scratch/Qwen2.5-0.5B and are newly initialized: ['value_head.weight'][32m [repeated 7x across cluster][0m
[36m(CriticRayActorBase pid=1560955, ip=10.224.3.43)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.[32m [repeated 7x across cluster][0m
[36m(CriticRayActorBase pid=3702113)[0m 2025-07-14 15:58:18.266 | INFO     | orz.ppo.models:get_llm_for_sequence_regression:572 - initialize value_head for ZeRO-3 reward model training.[32m [repeated 7x across cluster][0m
[36m(CriticRayActorBase pid=3702762)[0m Using /home/a/anokhin/.cache/torch_extensions/py312_cu122 as PyTorch extensions root...[32m [repeated 7x across cluster][0m
[36m(CriticRayActorBase pid=1560955, ip=10.224.3.43)[0m Loading extension module fused_adam...[32m [repeated 7x across cluster][0m
[36m(LLMActor pid=3700666)[0m Processed prompts:   1%|          | 1/91 [00:00<00:12,  7.10it/s, est. speed input: 1399.38 toks/s, output: 14.20 toks/s]
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m Processed prompts:   0%|          | 0/91 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][32m [repeated 7x across cluster][0m
[36m(LLMActor pid=3700666)[0m Processed prompts:  68%|██████▊   | 62/91 [00:05<00:04,  5.84it/s, est. speed input: 2308.55 toks/s, output: 1318.35 toks/s][32m [repeated 172x across cluster][0m
[36m(LLMActor pid=1559112, ip=10.224.3.43)[0m Processed prompts:  92%|█████████▏| 84/91 [00:08<00:03,  2.31it/s, est. speed input: 1909.89 toks/s, output: 1661.79 toks/s]
[36m(LLMActor pid=3700666)[0m Processed prompts:  89%|████████▉ | 81/91 [00:10<00:02,  4.84it/s, est. speed input: 1540.64 toks/s, output: 1770.24 toks/s][32m [repeated 90x across cluster][0m
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m Processed prompts:  97%|█████████▋| 88/91 [00:14<00:03,  1.01s/it, est. speed input: 2027.63 toks/s, output: 1467.38 toks/s][32m [repeated 23x across cluster][0m
[36m(LLMActor pid=3700666)[0m Processed prompts:  90%|█████████ | 82/91 [00:11<00:04,  2.14it/s, est. speed input: 1388.12 toks/s, output: 1650.60 toks/s][32m [repeated 8x across cluster][0m
[36m(LLMActor pid=1559114, ip=10.224.3.43)[0m Processed prompts: 100%|██████████| 91/91 [00:16<00:00,  2.04it/s, est. speed input: 2164.65 toks/s, output: 1498.02 toks/s]Processed prompts: 100%|██████████| 91/91 [00:16<00:00,  5.64it/s, est. speed input: 2164.65 toks/s, output: 1498.02 toks/s]
[36m(LLMActor pid=1559111, ip=10.224.3.43)[0m Processed prompts:  99%|█████████▉| 90/91 [00:18<00:01,  1.18s/it, est. speed input: 1195.91 toks/s, output: 1378.32 toks/s][32m [repeated 14x across cluster][0m
[36m(LLMActor pid=1559111, ip=10.224.3.43)[0m Processed prompts: 100%|██████████| 91/91 [00:19<00:00,  1.07s/it, est. speed input: 1167.47 toks/s, output: 1405.67 toks/s]Processed prompts: 100%|██████████| 91/91 [00:19<00:00,  4.72it/s, est. speed input: 1167.47 toks/s, output: 1405.67 toks/s]
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m Processed prompts: 100%|██████████| 91/91 [00:24<00:00,  2.12s/it, est. speed input: 1206.89 toks/s, output: 1073.38 toks/s]Processed prompts: 100%|██████████| 91/91 [00:24<00:00,  3.73it/s, est. speed input: 1206.89 toks/s, output: 1073.38 toks/s]
[36m(LLMActor pid=1559113, ip=10.224.3.43)[0m Processed prompts:  99%|█████████▉| 90/91 [00:24<00:02,  2.88s/it, est. speed input: 1196.07 toks/s, output: 999.31 toks/s] [32m [repeated 8x across cluster][0m
[36m(LLMActor pid=3700667)[0m Processed prompts:  99%|█████████▉| 90/91 [00:29<00:03,  3.82s/it, est. speed input: 641.24 toks/s, output: 824.67 toks/s] [32m [repeated 4x across cluster][0m
[36m(LLMActor pid=3700665)[0m Processed prompts: 100%|██████████| 91/91 [00:31<00:00,  3.86s/it, est. speed input: 620.03 toks/s, output: 820.50 toks/s]Processed prompts: 100%|██████████| 91/91 [00:31<00:00,  2.93it/s, est. speed input: 620.03 toks/s, output: 820.50 toks/s]
[36m(LLMActor pid=3700668)[0m Processed prompts:  99%|█████████▉| 90/91 [00:33<00:03,  3.94s/it, est. speed input: 593.08 toks/s, output: 836.39 toks/s]
[36m(LLMActor pid=3700668)[0m Processed prompts: 100%|██████████| 91/91 [00:48<00:00,  7.22s/it, est. speed input: 412.54 toks/s, output: 663.76 toks/s]Processed prompts: 100%|██████████| 91/91 [00:48<00:00,  1.88it/s, est. speed input: 412.54 toks/s, output: 663.76 toks/s][32m [repeated 2x across cluster][0m
[36m(LLMActor pid=3700666)[0m Processed prompts:  99%|█████████▉| 90/91 [00:53<00:09,  9.43s/it, est. speed input: 332.88 toks/s, output: 623.05 toks/s] 
[36m(LLMActor pid=3700666)[0m Processed prompts: 100%|██████████| 91/91 [01:18<00:00, 13.96s/it, est. speed input: 228.61 toks/s, output: 512.30 toks/s]Processed prompts: 100%|██████████| 91/91 [01:18<00:00,  1.16it/s, est. speed input: 228.61 toks/s, output: 512.30 toks/s]
[36m(LLMActor pid=1559112, ip=10.224.3.43)[0m Processed prompts:  99%|█████████▉| 90/91 [01:29<00:21, 21.05s/it, est. speed input: 207.87 toks/s, output: 327.14 toks/s]
[36m(LLMActor pid=1559112, ip=10.224.3.43)[0m Processed prompts: 100%|██████████| 91/91 [01:31<00:00, 15.58s/it, est. speed input: 204.35 toks/s, output: 405.83 toks/s]Processed prompts: 100%|██████████| 91/91 [01:31<00:00,  1.01s/it, est. speed input: 204.35 toks/s, output: 405.83 toks/s]
2025-07-14 16:00:12.129 | INFO     | playground.orz_7b_ppo:eval:497 - math500/response_len_in_char: 1000.0500,math500/accuracy: 0.0000,aime2024/response_len_in_char: 987.1000,aime2024/accuracy: 0.0000,gpqa_diamond/response_len_in_char: 950.0657,gpqa_diamond/accuracy: 0.0000,eval_accuracy: 0.0000
2025-07-14 16:00:12.160 | INFO     | orz.ppo.trainer:make_experience:227 - start generation
2025-07-14 16:02:53.367 | INFO     | orz.ppo.trainer:make_experience:230 - generate local rollout batch done
2025-07-14 16:02:53.598 | INFO     | orz.ppo.trainer:make_experience:234 - Offload vllm engines to cpu, time cost: 0.23s
2025-07-14 16:02:53.598 | INFO     | orz.ppo.trainer:make_experience:215 - Generate sequences via vllm engines, time cost: 161.44s
[36m(extract_final_answers_batch pid=1562208, ip=10.224.3.43)[0m [2025-07-14 16:02:55,665] [WARNING] [real_accelerator.py:174:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.
[36m(extract_final_answers_batch pid=1562208, ip=10.224.3.43)[0m [2025-07-14 16:02:55,668] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cpu (auto detect)
[36m(get_reflection_pattern_score pid=3704324)[0m math_verify is not installed in this environment
[36m(extract_final_answers_batch pid=3704325)[0m [2025-07-14 16:02:58,333] [WARNING] [real_accelerator.py:174:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.[32m [repeated 13x across cluster][0m
[36m(extract_final_answers_batch pid=3704325)[0m [2025-07-14 16:02:58,338] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cpu (auto detect)[32m [repeated 13x across cluster][0m
[36m(get_reflection_pattern_score pid=3706088)[0m math_verify is not installed in this environment[32m [repeated 14x across cluster][0m
[36m(extract_final_answers_batch pid=3705140)[0m [2025-07-14 16:03:06,353] [WARNING] [real_accelerator.py:174:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.[32m [repeated 33x across cluster][0m
[36m(extract_final_answers_batch pid=3705140)[0m [2025-07-14 16:03:06,358] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cpu (auto detect)[32m [repeated 33x across cluster][0m
2025-07-14 16:03:10.952 | INFO     | playground.orz_7b_ppo:custom_reward_fn:298 - avg_non_stop_count: 0.0018,avg_repeat_score: 0.0265,avg_reflection_pattern_score: 0.0134,avg_pass_at_n: 0.0078,avg_num_tokens: 350.2524,std_num_tokens: 668.7433,avg_correct_num_tokens: 41.0000,std_correct_num_tokens: 0.0000,avg_incorrect_num_tokens: 350.2902,std_incorrect_num_tokens: 668.7754
2025-07-14 16:03:11.658 | INFO     | orz.ppo.trainer:make_experience:245 - Calculate custom rewards, time cost: 18.06s
2025-07-14 16:03:14.335 | INFO     | orz.ppo.trainer:make_experience:260 - Packing samples, time cost: 2.67s
2025-07-14 16:27:05.282 | INFO     | orz.ppo.trainer:make_experience:282 - experiences size: 497
2025-07-14 16:27:05.283 | INFO     | orz.ppo.trainer:make_experience:273 - Inference and calculate values, log probs, rewards, kl divergence, time cost: 1430.95s
2025-07-14 16:27:07.162 | INFO     | orz.ppo.trainer:make_experience:299 - Calculate advantages and returns, time cost: 1.88s
2025-07-14 16:27:07.163 | INFO     | orz.ppo.trainer:make_experience:317 - avg_raw_rewards: 0.00011178180275548632, avg_kl: 0.0, avg_response_length: 482.04191435846525, avg_orm_score: 0.0, avg_custom_rewards: 0.00011178180275548632
2025-07-14 16:27:07.257 | INFO     | orz.ppo.trainer:train:129 - dumping replay buffer to orz_ckpt/orz_0p5b_ppo/dumped_replay_buffer/iter0_replay_buffer.jsonl
2025-07-14 16:27:12.857 | INFO     | orz.ppo.trainer:train:124 - Dumping replay buffer, time cost: 5.60s
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:   0%|          | 0/63 [00:00<?, ?it/s]
[36m(CriticRayActorBase pid=3702113)[0m Invalidate trace cache @ step 318 and module 0: cache has only 318 modules
[36m(pid=3706081)[0m math_verify is not installed in this environment[32m [repeated 42x across cluster][0m
[36m(pid=3706536)[0m [2025-07-14 16:03:06,654] [WARNING] [real_accelerator.py:174:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.[32m [repeated 41x across cluster][0m
[36m(pid=3706536)[0m [2025-07-14 16:03:06,658] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cpu (auto detect)[32m [repeated 41x across cluster][0m
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:   0%|          | 0/63 [00:28<?, ?it/s, critic_loss=0.00574, values=-0.138, critic_lr=0]Critic Train epoch [1/1]:   2%|▏         | 1/63 [00:28<29:44, 28.78s/it, critic_loss=0.00574, values=-0.138, critic_lr=0]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:   2%|▏         | 1/63 [00:55<29:44, 28.78s/it, critic_loss=0.00626, values=-0.145, critic_lr=0]Critic Train epoch [1/1]:   3%|▎         | 2/63 [00:55<27:56, 27.49s/it, critic_loss=0.00626, values=-0.145, critic_lr=0]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:   3%|▎         | 2/63 [01:17<27:56, 27.49s/it, critic_loss=0.00599, values=-0.105, critic_lr=0]Critic Train epoch [1/1]:   5%|▍         | 3/63 [01:17<24:49, 24.82s/it, critic_loss=0.00599, values=-0.105, critic_lr=0]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:   5%|▍         | 3/63 [01:38<24:49, 24.82s/it, critic_loss=0.00536, values=-0.124, critic_lr=0]Critic Train epoch [1/1]:   6%|▋         | 4/63 [01:38<22:58, 23.37s/it, critic_loss=0.00536, values=-0.124, critic_lr=0]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:   6%|▋         | 4/63 [01:59<22:58, 23.37s/it, critic_loss=0.00664, values=-0.0952, critic_lr=1e-7]Critic Train epoch [1/1]:   8%|▊         | 5/63 [01:59<21:51, 22.61s/it, critic_loss=0.00664, values=-0.0952, critic_lr=1e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:   8%|▊         | 5/63 [02:22<21:51, 22.61s/it, critic_loss=0.00597, values=-0.152, critic_lr=1e-7] Critic Train epoch [1/1]:  10%|▉         | 6/63 [02:22<21:40, 22.81s/it, critic_loss=0.00597, values=-0.152, critic_lr=1e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  10%|▉         | 6/63 [02:43<21:40, 22.81s/it, critic_loss=0.00553, values=-0.131, critic_lr=1e-7]Critic Train epoch [1/1]:  11%|█         | 7/63 [02:43<20:46, 22.27s/it, critic_loss=0.00553, values=-0.131, critic_lr=1e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  11%|█         | 7/63 [03:04<20:46, 22.27s/it, critic_loss=0.00545, values=-0.129, critic_lr=1e-7]Critic Train epoch [1/1]:  13%|█▎        | 8/63 [03:04<20:05, 21.91s/it, critic_loss=0.00545, values=-0.129, critic_lr=1e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  13%|█▎        | 8/63 [03:26<20:05, 21.91s/it, critic_loss=0.00594, values=-0.136, critic_lr=1e-7]Critic Train epoch [1/1]:  14%|█▍        | 9/63 [03:26<19:30, 21.67s/it, critic_loss=0.00594, values=-0.136, critic_lr=1e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  14%|█▍        | 9/63 [03:47<19:30, 21.67s/it, critic_loss=0.0055, values=-0.125, critic_lr=2e-7] Critic Train epoch [1/1]:  16%|█▌        | 10/63 [03:47<19:01, 21.53s/it, critic_loss=0.0055, values=-0.125, critic_lr=2e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  16%|█▌        | 10/63 [04:10<19:01, 21.53s/it, critic_loss=0.00558, values=-0.123, critic_lr=2e-7]Critic Train epoch [1/1]:  17%|█▋        | 11/63 [04:10<19:05, 22.04s/it, critic_loss=0.00558, values=-0.123, critic_lr=2e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  17%|█▋        | 11/63 [04:31<19:05, 22.04s/it, critic_loss=0.00557, values=-0.132, critic_lr=2e-7]Critic Train epoch [1/1]:  19%|█▉        | 12/63 [04:31<18:29, 21.76s/it, critic_loss=0.00557, values=-0.132, critic_lr=2e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  19%|█▉        | 12/63 [04:52<18:29, 21.76s/it, critic_loss=0.00565, values=-0.13, critic_lr=2e-7] Critic Train epoch [1/1]:  21%|██        | 13/63 [04:52<17:58, 21.58s/it, critic_loss=0.00565, values=-0.13, critic_lr=2e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  21%|██        | 13/63 [05:13<17:58, 21.58s/it, critic_loss=0.00729, values=-0.175, critic_lr=2e-7]Critic Train epoch [1/1]:  22%|██▏       | 14/63 [05:13<17:30, 21.45s/it, critic_loss=0.00729, values=-0.175, critic_lr=2e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  22%|██▏       | 14/63 [05:35<17:30, 21.45s/it, critic_loss=0.00581, values=-0.13, critic_lr=3e-7] Critic Train epoch [1/1]:  24%|██▍       | 15/63 [05:35<17:06, 21.38s/it, critic_loss=0.00581, values=-0.13, critic_lr=3e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  24%|██▍       | 15/63 [05:58<17:06, 21.38s/it, critic_loss=0.00545, values=-0.122, critic_lr=3e-7]Critic Train epoch [1/1]:  25%|██▌       | 16/63 [05:58<17:10, 21.92s/it, critic_loss=0.00545, values=-0.122, critic_lr=3e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  25%|██▌       | 16/63 [06:19<17:10, 21.92s/it, critic_loss=0.00631, values=-0.135, critic_lr=3e-7]Critic Train epoch [1/1]:  27%|██▋       | 17/63 [06:19<16:38, 21.70s/it, critic_loss=0.00631, values=-0.135, critic_lr=3e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  27%|██▋       | 17/63 [06:40<16:38, 21.70s/it, critic_loss=0.0055, values=-0.135, critic_lr=3e-7] Critic Train epoch [1/1]:  29%|██▊       | 18/63 [06:40<16:08, 21.53s/it, critic_loss=0.0055, values=-0.135, critic_lr=3e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  29%|██▊       | 18/63 [07:01<16:08, 21.53s/it, critic_loss=0.00547, values=-0.135, critic_lr=3e-7]Critic Train epoch [1/1]:  30%|███       | 19/63 [07:01<15:42, 21.41s/it, critic_loss=0.00547, values=-0.135, critic_lr=3e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  30%|███       | 19/63 [07:22<15:42, 21.41s/it, critic_loss=0.00597, values=-0.146, critic_lr=4e-7]Critic Train epoch [1/1]:  32%|███▏      | 20/63 [07:22<15:18, 21.36s/it, critic_loss=0.00597, values=-0.146, critic_lr=4e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  32%|███▏      | 20/63 [07:46<15:18, 21.36s/it, critic_loss=0.00606, values=-0.147, critic_lr=4e-7]Critic Train epoch [1/1]:  33%|███▎      | 21/63 [07:46<15:20, 21.91s/it, critic_loss=0.00606, values=-0.147, critic_lr=4e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  33%|███▎      | 21/63 [08:07<15:20, 21.91s/it, critic_loss=0.00656, values=-0.128, critic_lr=4e-7]Critic Train epoch [1/1]:  35%|███▍      | 22/63 [08:07<14:48, 21.68s/it, critic_loss=0.00656, values=-0.128, critic_lr=4e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  35%|███▍      | 22/63 [08:28<14:48, 21.68s/it, critic_loss=0.00592, values=-0.14, critic_lr=4e-7] Critic Train epoch [1/1]:  37%|███▋      | 23/63 [08:28<14:20, 21.52s/it, critic_loss=0.00592, values=-0.14, critic_lr=4e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  37%|███▋      | 23/63 [08:49<14:20, 21.52s/it, critic_loss=0.00573, values=-0.145, critic_lr=4e-7]Critic Train epoch [1/1]:  38%|███▊      | 24/63 [08:49<13:54, 21.41s/it, critic_loss=0.00573, values=-0.145, critic_lr=4e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  38%|███▊      | 24/63 [09:10<13:54, 21.41s/it, critic_loss=0.00584, values=-0.132, critic_lr=5e-7]Critic Train epoch [1/1]:  40%|███▉      | 25/63 [09:10<13:31, 21.35s/it, critic_loss=0.00584, values=-0.132, critic_lr=5e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  40%|███▉      | 25/63 [09:34<13:31, 21.35s/it, critic_loss=0.00661, values=-0.133, critic_lr=5e-7]Critic Train epoch [1/1]:  41%|████▏     | 26/63 [09:34<13:30, 21.90s/it, critic_loss=0.00661, values=-0.133, critic_lr=5e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  41%|████▏     | 26/63 [09:55<13:30, 21.90s/it, critic_loss=0.00577, values=-0.137, critic_lr=5e-7]Critic Train epoch [1/1]:  43%|████▎     | 27/63 [09:55<13:03, 21.75s/it, critic_loss=0.00577, values=-0.137, critic_lr=5e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  43%|████▎     | 27/63 [10:16<13:03, 21.75s/it, critic_loss=0.00578, values=-0.14, critic_lr=5e-7] Critic Train epoch [1/1]:  44%|████▍     | 28/63 [10:16<12:35, 21.58s/it, critic_loss=0.00578, values=-0.14, critic_lr=5e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  44%|████▍     | 28/63 [10:37<12:35, 21.58s/it, critic_loss=0.00761, values=-0.135, critic_lr=5e-7]Critic Train epoch [1/1]:  46%|████▌     | 29/63 [10:37<12:09, 21.45s/it, critic_loss=0.00761, values=-0.135, critic_lr=5e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  46%|████▌     | 29/63 [10:58<12:09, 21.45s/it, critic_loss=0.00602, values=-0.106, critic_lr=6e-7]Critic Train epoch [1/1]:  48%|████▊     | 30/63 [10:58<11:45, 21.38s/it, critic_loss=0.00602, values=-0.106, critic_lr=6e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  48%|████▊     | 30/63 [11:22<11:45, 21.38s/it, critic_loss=0.00554, values=-0.128, critic_lr=6e-7]Critic Train epoch [1/1]:  49%|████▉     | 31/63 [11:22<11:41, 21.92s/it, critic_loss=0.00554, values=-0.128, critic_lr=6e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  49%|████▉     | 31/63 [11:43<11:41, 21.92s/it, critic_loss=0.00647, values=-0.108, critic_lr=6e-7]Critic Train epoch [1/1]:  51%|█████     | 32/63 [11:43<11:12, 21.69s/it, critic_loss=0.00647, values=-0.108, critic_lr=6e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  51%|█████     | 32/63 [12:04<11:12, 21.69s/it, critic_loss=0.00521, values=-0.112, critic_lr=6e-7]Critic Train epoch [1/1]:  52%|█████▏    | 33/63 [12:04<10:45, 21.53s/it, critic_loss=0.00521, values=-0.112, critic_lr=6e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  52%|█████▏    | 33/63 [12:25<10:45, 21.53s/it, critic_loss=0.00564, values=-0.128, critic_lr=6e-7]Critic Train epoch [1/1]:  54%|█████▍    | 34/63 [12:25<10:20, 21.41s/it, critic_loss=0.00564, values=-0.128, critic_lr=6e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  54%|█████▍    | 34/63 [12:46<10:20, 21.41s/it, critic_loss=0.00517, values=-0.128, critic_lr=7e-7]Critic Train epoch [1/1]:  56%|█████▌    | 35/63 [12:46<09:57, 21.35s/it, critic_loss=0.00517, values=-0.128, critic_lr=7e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  56%|█████▌    | 35/63 [13:09<09:57, 21.35s/it, critic_loss=0.00662, values=-0.119, critic_lr=7e-7]Critic Train epoch [1/1]:  57%|█████▋    | 36/63 [13:09<09:51, 21.90s/it, critic_loss=0.00662, values=-0.119, critic_lr=7e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  57%|█████▋    | 36/63 [13:31<09:51, 21.90s/it, critic_loss=0.00548, values=-0.123, critic_lr=7e-7]Critic Train epoch [1/1]:  59%|█████▊    | 37/63 [13:31<09:23, 21.67s/it, critic_loss=0.00548, values=-0.123, critic_lr=7e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  59%|█████▊    | 37/63 [13:52<09:23, 21.67s/it, critic_loss=0.00587, values=-0.124, critic_lr=7e-7]Critic Train epoch [1/1]:  60%|██████    | 38/63 [13:52<08:57, 21.51s/it, critic_loss=0.00587, values=-0.124, critic_lr=7e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  60%|██████    | 38/63 [14:13<08:57, 21.51s/it, critic_loss=0.00577, values=-0.145, critic_lr=7e-7]Critic Train epoch [1/1]:  62%|██████▏   | 39/63 [14:13<08:33, 21.40s/it, critic_loss=0.00577, values=-0.145, critic_lr=7e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  62%|██████▏   | 39/63 [14:34<08:33, 21.40s/it, critic_loss=0.00564, values=-0.138, critic_lr=8e-7]Critic Train epoch [1/1]:  63%|██████▎   | 40/63 [14:34<08:10, 21.35s/it, critic_loss=0.00564, values=-0.138, critic_lr=8e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  63%|██████▎   | 40/63 [14:57<08:10, 21.35s/it, critic_loss=0.00558, values=-0.129, critic_lr=8e-7]Critic Train epoch [1/1]:  65%|██████▌   | 41/63 [14:57<08:01, 21.90s/it, critic_loss=0.00558, values=-0.129, critic_lr=8e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  65%|██████▌   | 41/63 [15:18<08:01, 21.90s/it, critic_loss=0.0053, values=-0.109, critic_lr=8e-7] Critic Train epoch [1/1]:  67%|██████▋   | 42/63 [15:18<07:35, 21.67s/it, critic_loss=0.0053, values=-0.109, critic_lr=8e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  67%|██████▋   | 42/63 [15:40<07:35, 21.67s/it, critic_loss=0.00541, values=-0.124, critic_lr=8e-7]Critic Train epoch [1/1]:  68%|██████▊   | 43/63 [15:40<07:10, 21.51s/it, critic_loss=0.00541, values=-0.124, critic_lr=8e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  68%|██████▊   | 43/63 [16:01<07:10, 21.51s/it, critic_loss=0.00555, values=-0.144, critic_lr=8e-7]Critic Train epoch [1/1]:  70%|██████▉   | 44/63 [16:01<06:46, 21.40s/it, critic_loss=0.00555, values=-0.144, critic_lr=8e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  70%|██████▉   | 44/63 [16:22<06:46, 21.40s/it, critic_loss=0.00706, values=-0.106, critic_lr=9e-7]Critic Train epoch [1/1]:  71%|███████▏  | 45/63 [16:22<06:24, 21.35s/it, critic_loss=0.00706, values=-0.106, critic_lr=9e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  71%|███████▏  | 45/63 [16:45<06:24, 21.35s/it, critic_loss=0.00529, values=-0.114, critic_lr=9e-7]Critic Train epoch [1/1]:  73%|███████▎  | 46/63 [16:45<06:12, 21.90s/it, critic_loss=0.00529, values=-0.114, critic_lr=9e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  73%|███████▎  | 46/63 [17:06<06:12, 21.90s/it, critic_loss=0.00579, values=-0.125, critic_lr=9e-7]Critic Train epoch [1/1]:  75%|███████▍  | 47/63 [17:06<05:46, 21.67s/it, critic_loss=0.00579, values=-0.125, critic_lr=9e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  75%|███████▍  | 47/63 [17:27<05:46, 21.67s/it, critic_loss=0.0059, values=-0.116, critic_lr=9e-7] Critic Train epoch [1/1]:  76%|███████▌  | 48/63 [17:27<05:22, 21.51s/it, critic_loss=0.0059, values=-0.116, critic_lr=9e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  76%|███████▌  | 48/63 [17:49<05:22, 21.51s/it, critic_loss=0.00553, values=-0.124, critic_lr=9e-7]Critic Train epoch [1/1]:  78%|███████▊  | 49/63 [17:49<04:59, 21.41s/it, critic_loss=0.00553, values=-0.124, critic_lr=9e-7]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  78%|███████▊  | 49/63 [18:10<04:59, 21.41s/it, critic_loss=0.00492, values=-0.0975, critic_lr=1e-6]Critic Train epoch [1/1]:  79%|███████▉  | 50/63 [18:10<04:37, 21.35s/it, critic_loss=0.00492, values=-0.0975, critic_lr=1e-6]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  79%|███████▉  | 50/63 [18:33<04:37, 21.35s/it, critic_loss=0.00531, values=-0.103, critic_lr=1e-6] Critic Train epoch [1/1]:  81%|████████  | 51/63 [18:33<04:22, 21.90s/it, critic_loss=0.00531, values=-0.103, critic_lr=1e-6]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  81%|████████  | 51/63 [18:54<04:22, 21.90s/it, critic_loss=0.00502, values=-0.0957, critic_lr=1e-6]Critic Train epoch [1/1]:  83%|████████▎ | 52/63 [18:54<03:58, 21.67s/it, critic_loss=0.00502, values=-0.0957, critic_lr=1e-6]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  83%|████████▎ | 52/63 [19:15<03:58, 21.67s/it, critic_loss=0.00467, values=-0.0925, critic_lr=1e-6]Critic Train epoch [1/1]:  84%|████████▍ | 53/63 [19:15<03:35, 21.51s/it, critic_loss=0.00467, values=-0.0925, critic_lr=1e-6]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  84%|████████▍ | 53/63 [19:36<03:35, 21.51s/it, critic_loss=0.00497, values=-0.109, critic_lr=1e-6] Critic Train epoch [1/1]:  86%|████████▌ | 54/63 [19:36<03:12, 21.40s/it, critic_loss=0.00497, values=-0.109, critic_lr=1e-6]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  86%|████████▌ | 54/63 [19:58<03:12, 21.40s/it, critic_loss=0.00479, values=-0.103, critic_lr=1.1e-6]Critic Train epoch [1/1]:  87%|████████▋ | 55/63 [19:58<02:50, 21.34s/it, critic_loss=0.00479, values=-0.103, critic_lr=1.1e-6]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  87%|████████▋ | 55/63 [20:21<02:50, 21.34s/it, critic_loss=0.00463, values=-0.0991, critic_lr=1.1e-6]Critic Train epoch [1/1]:  89%|████████▉ | 56/63 [20:21<02:33, 21.90s/it, critic_loss=0.00463, values=-0.0991, critic_lr=1.1e-6]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  89%|████████▉ | 56/63 [20:42<02:33, 21.90s/it, critic_loss=0.00451, values=-0.0829, critic_lr=1.1e-6]Critic Train epoch [1/1]:  90%|█████████ | 57/63 [20:42<02:10, 21.75s/it, critic_loss=0.00451, values=-0.0829, critic_lr=1.1e-6]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  90%|█████████ | 57/63 [21:03<02:10, 21.75s/it, critic_loss=0.00533, values=-0.083, critic_lr=1.1e-6] Critic Train epoch [1/1]:  92%|█████████▏| 58/63 [21:03<01:47, 21.57s/it, critic_loss=0.00533, values=-0.083, critic_lr=1.1e-6]
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  92%|█████████▏| 58/63 [21:24<01:47, 21.57s/it, critic_loss=0.00474, values=-0.0732, critic_lr=1.1e-6]Critic Train epoch [1/1]:  94%|█████████▎| 59/63 [21:24<01:25, 21.45s/it, critic_loss=0.00474, values=-0.0732, critic_lr=1.1e-6]
2025-07-14 16:48:59.534 | INFO     | orz.ppo.trainer:ppo_local_train_critic:748 - Critic model training, time cost: 1306.32s
[36m(CriticRayActorBase pid=3702113)[0m Critic Train epoch [1/1]:  94%|█████████▎| 59/63 [21:46<01:25, 21.45s/it, critic_loss=0.00537, values=-0.113, critic_lr=1.2e-6] Critic Train epoch [1/1]:  94%|█████████▎| 59/63 [21:46<01:28, 22.14s/it, critic_loss=0.00537, values=-0.113, critic_lr=1.2e-6]
2025-07-14 16:49:00.094 | INFO     | orz.ppo.trainer:train:144 - Critic model training, time cost: 1306.94s
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:   0%|          | 0/63 [00:00<?, ?it/s]
[36m(PolicyRayActorBase pid=3701267)[0m Invalidate trace cache @ step 318 and module 0: cache has only 318 modules
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:   0%|          | 0/63 [00:30<?, ?it/s, pg=-0.014, ret=0, glen=311, tlen=535, kl=0, act_lr=0, ent=1.47]Actor Train epoch [1/1]:   2%|▏         | 1/63 [00:30<31:48, 30.78s/it, pg=-0.014, ret=0, glen=311, tlen=535, kl=0, act_lr=0, ent=1.47]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:   2%|▏         | 1/63 [01:01<31:48, 30.78s/it, pg=-0.0266, ret=0, glen=351, tlen=578, kl=0, act_lr=0, ent=1.54]Actor Train epoch [1/1]:   3%|▎         | 2/63 [01:01<31:15, 30.74s/it, pg=-0.0266, ret=0, glen=351, tlen=578, kl=0, act_lr=0, ent=1.54]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:   3%|▎         | 2/63 [01:23<31:15, 30.74s/it, pg=-0.206, ret=0, glen=915, tlen=1.13e+3, kl=0, act_lr=0, ent=2.5]Actor Train epoch [1/1]:   5%|▍         | 3/63 [01:23<26:34, 26.57s/it, pg=-0.206, ret=0, glen=915, tlen=1.13e+3, kl=0, act_lr=0, ent=2.5]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:   5%|▍         | 3/63 [01:44<26:34, 26.57s/it, pg=0.0361, ret=0, glen=303, tlen=511, kl=0, act_lr=0, ent=1.52]   Actor Train epoch [1/1]:   6%|▋         | 4/63 [01:44<24:02, 24.44s/it, pg=0.0361, ret=0, glen=303, tlen=511, kl=0, act_lr=0, ent=1.52]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:   6%|▋         | 4/63 [02:05<24:02, 24.44s/it, pg=-0.0367, ret=0, glen=298, tlen=507, kl=0, act_lr=0, ent=1.57]Actor Train epoch [1/1]:   8%|▊         | 5/63 [02:05<22:29, 23.27s/it, pg=-0.0367, ret=0, glen=298, tlen=507, kl=0, act_lr=0, ent=1.57]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:   8%|▊         | 5/63 [02:26<22:29, 23.27s/it, pg=-0.0675, ret=0, glen=392, tlen=600, kl=0, act_lr=0, ent=1.61]Actor Train epoch [1/1]:  10%|▉         | 6/63 [02:26<21:26, 22.57s/it, pg=-0.0675, ret=0, glen=392, tlen=600, kl=0, act_lr=0, ent=1.61]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  10%|▉         | 6/63 [02:47<21:26, 22.57s/it, pg=0.00549, ret=0.000386, glen=424, tlen=632, kl=0, act_lr=0, ent=1.14]Actor Train epoch [1/1]:  11%|█         | 7/63 [02:47<20:38, 22.11s/it, pg=0.00549, ret=0.000386, glen=424, tlen=632, kl=0, act_lr=0, ent=1.14]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  11%|█         | 7/63 [03:09<20:38, 22.11s/it, pg=-0.0245, ret=0, glen=530, tlen=755, kl=0, act_lr=0, ent=2.57]       Actor Train epoch [1/1]:  13%|█▎        | 8/63 [03:09<19:59, 21.81s/it, pg=-0.0245, ret=0, glen=530, tlen=755, kl=0, act_lr=0, ent=2.57]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  13%|█▎        | 8/63 [03:30<19:59, 21.81s/it, pg=-0.062, ret=0, glen=578, tlen=801, kl=0, act_lr=0, ent=1.89] Actor Train epoch [1/1]:  14%|█▍        | 9/63 [03:30<19:27, 21.62s/it, pg=-0.062, ret=0, glen=578, tlen=801, kl=0, act_lr=0, ent=1.89]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  14%|█▍        | 9/63 [03:51<19:27, 21.62s/it, pg=0.00481, ret=0, glen=281, tlen=502, kl=0, act_lr=0, ent=1.62]Actor Train epoch [1/1]:  16%|█▌        | 10/63 [03:51<18:58, 21.48s/it, pg=0.00481, ret=0, glen=281, tlen=502, kl=0, act_lr=0, ent=1.62]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  16%|█▌        | 10/63 [04:12<18:58, 21.48s/it, pg=-0.00385, ret=0, glen=565, tlen=775, kl=0, act_lr=0, ent=1.31]Actor Train epoch [1/1]:  17%|█▋        | 11/63 [04:12<18:31, 21.38s/it, pg=-0.00385, ret=0, glen=565, tlen=775, kl=0, act_lr=0, ent=1.31]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  17%|█▋        | 11/63 [04:33<18:31, 21.38s/it, pg=-0.107, ret=0, glen=418, tlen=629, kl=0, act_lr=0, ent=2.04]  Actor Train epoch [1/1]:  19%|█▉        | 12/63 [04:33<18:07, 21.31s/it, pg=-0.107, ret=0, glen=418, tlen=629, kl=0, act_lr=0, ent=2.04]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  19%|█▉        | 12/63 [04:54<18:07, 21.31s/it, pg=0.00277, ret=0, glen=305, tlen=517, kl=0, act_lr=0, ent=1.46]Actor Train epoch [1/1]:  21%|██        | 13/63 [04:54<17:43, 21.27s/it, pg=0.00277, ret=0, glen=305, tlen=517, kl=0, act_lr=0, ent=1.46]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  21%|██        | 13/63 [05:16<17:43, 21.27s/it, pg=0.0421, ret=0, glen=403, tlen=614, kl=0, act_lr=0, ent=1.27] Actor Train epoch [1/1]:  22%|██▏       | 14/63 [05:16<17:20, 21.23s/it, pg=0.0421, ret=0, glen=403, tlen=614, kl=0, act_lr=0, ent=1.27]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  22%|██▏       | 14/63 [05:37<17:20, 21.23s/it, pg=0.0748, ret=0, glen=375, tlen=590, kl=0, act_lr=0, ent=2.29]Actor Train epoch [1/1]:  24%|██▍       | 15/63 [05:37<16:58, 21.21s/it, pg=0.0748, ret=0, glen=375, tlen=590, kl=0, act_lr=0, ent=2.29]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  24%|██▍       | 15/63 [05:58<16:58, 21.21s/it, pg=0.103, ret=0, glen=635, tlen=845, kl=0, act_lr=0, ent=1.89] Actor Train epoch [1/1]:  25%|██▌       | 16/63 [05:58<16:36, 21.20s/it, pg=0.103, ret=0, glen=635, tlen=845, kl=0, act_lr=0, ent=1.89]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  25%|██▌       | 16/63 [06:19<16:36, 21.20s/it, pg=0.093, ret=0, glen=357, tlen=570, kl=0, act_lr=0, ent=1.24]Actor Train epoch [1/1]:  27%|██▋       | 17/63 [06:19<16:14, 21.19s/it, pg=0.093, ret=0, glen=357, tlen=570, kl=0, act_lr=0, ent=1.24]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  27%|██▋       | 17/63 [06:40<16:14, 21.19s/it, pg=0.0194, ret=0, glen=315, tlen=528, kl=0, act_lr=0, ent=1.48]Actor Train epoch [1/1]:  29%|██▊       | 18/63 [06:40<15:53, 21.19s/it, pg=0.0194, ret=0, glen=315, tlen=528, kl=0, act_lr=0, ent=1.48]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  29%|██▊       | 18/63 [07:01<15:53, 21.19s/it, pg=0.113, ret=0, glen=400, tlen=611, kl=0, act_lr=0, ent=1.41] Actor Train epoch [1/1]:  30%|███       | 19/63 [07:01<15:31, 21.18s/it, pg=0.113, ret=0, glen=400, tlen=611, kl=0, act_lr=0, ent=1.41]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  30%|███       | 19/63 [07:23<15:31, 21.18s/it, pg=-0.00535, ret=0, glen=365, tlen=573, kl=0, act_lr=0, ent=1.51]Actor Train epoch [1/1]:  32%|███▏      | 20/63 [07:23<15:10, 21.17s/it, pg=-0.00535, ret=0, glen=365, tlen=573, kl=0, act_lr=0, ent=1.51]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  32%|███▏      | 20/63 [07:44<15:10, 21.17s/it, pg=0.0615, ret=0, glen=369, tlen=584, kl=0, act_lr=0, ent=1.21]  Actor Train epoch [1/1]:  33%|███▎      | 21/63 [07:44<14:49, 21.17s/it, pg=0.0615, ret=0, glen=369, tlen=584, kl=0, act_lr=0, ent=1.21]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  33%|███▎      | 21/63 [08:05<14:49, 21.17s/it, pg=-0.0235, ret=0, glen=884, tlen=1.09e+3, kl=0, act_lr=0, ent=1.77]Actor Train epoch [1/1]:  35%|███▍      | 22/63 [08:05<14:27, 21.17s/it, pg=-0.0235, ret=0, glen=884, tlen=1.09e+3, kl=0, act_lr=0, ent=1.77]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  35%|███▍      | 22/63 [08:26<14:27, 21.17s/it, pg=-0.0159, ret=0, glen=336, tlen=549, kl=0, act_lr=0, ent=1.33]    Actor Train epoch [1/1]:  37%|███▋      | 23/63 [08:26<14:06, 21.16s/it, pg=-0.0159, ret=0, glen=336, tlen=549, kl=0, act_lr=0, ent=1.33]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  37%|███▋      | 23/63 [08:47<14:06, 21.16s/it, pg=0.178, ret=0, glen=1.46e+3, tlen=1.68e+3, kl=0, act_lr=0, ent=1.38]Actor Train epoch [1/1]:  38%|███▊      | 24/63 [08:47<13:45, 21.16s/it, pg=0.178, ret=0, glen=1.46e+3, tlen=1.68e+3, kl=0, act_lr=0, ent=1.38]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  38%|███▊      | 24/63 [09:08<13:45, 21.16s/it, pg=-0.037, ret=0, glen=330, tlen=558, kl=0, act_lr=0, ent=1.66]       Actor Train epoch [1/1]:  40%|███▉      | 25/63 [09:08<13:24, 21.16s/it, pg=-0.037, ret=0, glen=330, tlen=558, kl=0, act_lr=0, ent=1.66]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  40%|███▉      | 25/63 [09:29<13:24, 21.16s/it, pg=-0.0726, ret=0, glen=641, tlen=851, kl=0, act_lr=0, ent=2.01]Actor Train epoch [1/1]:  41%|████▏     | 26/63 [09:29<13:02, 21.16s/it, pg=-0.0726, ret=0, glen=641, tlen=851, kl=0, act_lr=0, ent=2.01]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  41%|████▏     | 26/63 [09:51<13:02, 21.16s/it, pg=-0.0423, ret=0, glen=392, tlen=622, kl=0, act_lr=0, ent=2.08]Actor Train epoch [1/1]:  43%|████▎     | 27/63 [09:51<12:44, 21.23s/it, pg=-0.0423, ret=0, glen=392, tlen=622, kl=0, act_lr=0, ent=2.08]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  43%|████▎     | 27/63 [10:12<12:44, 21.23s/it, pg=-0.0203, ret=0, glen=448, tlen=659, kl=0, act_lr=0, ent=2.1] Actor Train epoch [1/1]:  44%|████▍     | 28/63 [10:12<12:22, 21.21s/it, pg=-0.0203, ret=0, glen=448, tlen=659, kl=0, act_lr=0, ent=2.1]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  44%|████▍     | 28/63 [10:33<12:22, 21.21s/it, pg=0.0465, ret=0, glen=357, tlen=579, kl=0, act_lr=0, ent=1.39]Actor Train epoch [1/1]:  46%|████▌     | 29/63 [10:33<12:00, 21.19s/it, pg=0.0465, ret=0, glen=357, tlen=579, kl=0, act_lr=0, ent=1.39]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  46%|████▌     | 29/63 [10:54<12:00, 21.19s/it, pg=-0.0935, ret=0, glen=853, tlen=1.06e+3, kl=0, act_lr=0, ent=2.12]Actor Train epoch [1/1]:  48%|████▊     | 30/63 [10:54<11:38, 21.18s/it, pg=-0.0935, ret=0, glen=853, tlen=1.06e+3, kl=0, act_lr=0, ent=2.12]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  48%|████▊     | 30/63 [11:16<11:38, 21.18s/it, pg=0.0182, ret=0, glen=455, tlen=670, kl=0, act_lr=0, ent=1.64]     Actor Train epoch [1/1]:  49%|████▉     | 31/63 [11:16<11:17, 21.17s/it, pg=0.0182, ret=0, glen=455, tlen=670, kl=0, act_lr=0, ent=1.64]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  49%|████▉     | 31/63 [11:37<11:17, 21.17s/it, pg=0.0163, ret=0, glen=719, tlen=948, kl=0, act_lr=0, ent=1.61]Actor Train epoch [1/1]:  51%|█████     | 32/63 [11:37<10:56, 21.17s/it, pg=0.0163, ret=0, glen=719, tlen=948, kl=0, act_lr=0, ent=1.61]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  51%|█████     | 32/63 [11:58<10:56, 21.17s/it, pg=-0.0373, ret=0, glen=339, tlen=548, kl=0, act_lr=0, ent=1.2]Actor Train epoch [1/1]:  52%|█████▏    | 33/63 [11:58<10:35, 21.17s/it, pg=-0.0373, ret=0, glen=339, tlen=548, kl=0, act_lr=0, ent=1.2]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  52%|█████▏    | 33/63 [12:19<10:35, 21.17s/it, pg=-0.00233, ret=0, glen=306, tlen=519, kl=0, act_lr=0, ent=1.4]Actor Train epoch [1/1]:  54%|█████▍    | 34/63 [12:19<10:14, 21.18s/it, pg=-0.00233, ret=0, glen=306, tlen=519, kl=0, act_lr=0, ent=1.4]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  54%|█████▍    | 34/63 [12:40<10:14, 21.18s/it, pg=-0.111, ret=0, glen=607, tlen=851, kl=0, act_lr=0, ent=1.55] Actor Train epoch [1/1]:  56%|█████▌    | 35/63 [12:40<09:52, 21.18s/it, pg=-0.111, ret=0, glen=607, tlen=851, kl=0, act_lr=0, ent=1.55]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  56%|█████▌    | 35/63 [13:01<09:52, 21.18s/it, pg=-0.0877, ret=0, glen=399, tlen=622, kl=0, act_lr=0, ent=1.47]Actor Train epoch [1/1]:  57%|█████▋    | 36/63 [13:01<09:31, 21.18s/it, pg=-0.0877, ret=0, glen=399, tlen=622, kl=0, act_lr=0, ent=1.47]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  57%|█████▋    | 36/63 [13:23<09:31, 21.18s/it, pg=-0.067, ret=0, glen=296, tlen=514, kl=0, act_lr=0, ent=1.84] Actor Train epoch [1/1]:  59%|█████▊    | 37/63 [13:23<09:10, 21.17s/it, pg=-0.067, ret=0, glen=296, tlen=514, kl=0, act_lr=0, ent=1.84]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  59%|█████▊    | 37/63 [13:44<09:10, 21.17s/it, pg=0.0081, ret=0, glen=394, tlen=600, kl=0, act_lr=0, ent=1.62]Actor Train epoch [1/1]:  60%|██████    | 38/63 [13:44<08:49, 21.17s/it, pg=0.0081, ret=0, glen=394, tlen=600, kl=0, act_lr=0, ent=1.62]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  60%|██████    | 38/63 [14:05<08:49, 21.17s/it, pg=0.00933, ret=0, glen=289, tlen=510, kl=0, act_lr=0, ent=1.81]Actor Train epoch [1/1]:  62%|██████▏   | 39/63 [14:05<08:27, 21.16s/it, pg=0.00933, ret=0, glen=289, tlen=510, kl=0, act_lr=0, ent=1.81]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  62%|██████▏   | 39/63 [14:26<08:27, 21.16s/it, pg=0.00941, ret=0, glen=455, tlen=669, kl=0, act_lr=0, ent=1.7] Actor Train epoch [1/1]:  63%|██████▎   | 40/63 [14:26<08:07, 21.18s/it, pg=0.00941, ret=0, glen=455, tlen=669, kl=0, act_lr=0, ent=1.7]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  63%|██████▎   | 40/63 [14:47<08:07, 21.18s/it, pg=-0.0326, ret=0, glen=288, tlen=495, kl=0, act_lr=0, ent=1.26]Actor Train epoch [1/1]:  65%|██████▌   | 41/63 [14:47<07:45, 21.17s/it, pg=-0.0326, ret=0, glen=288, tlen=495, kl=0, act_lr=0, ent=1.26]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  65%|██████▌   | 41/63 [15:08<07:45, 21.17s/it, pg=-0.0948, ret=0, glen=335, tlen=560, kl=0, act_lr=0, ent=1.45]Actor Train epoch [1/1]:  67%|██████▋   | 42/63 [15:08<07:24, 21.17s/it, pg=-0.0948, ret=0, glen=335, tlen=560, kl=0, act_lr=0, ent=1.45]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  67%|██████▋   | 42/63 [15:30<07:24, 21.17s/it, pg=0.00324, ret=0, glen=267, tlen=495, kl=0, act_lr=0, ent=1.58]Actor Train epoch [1/1]:  68%|██████▊   | 43/63 [15:30<07:03, 21.16s/it, pg=0.00324, ret=0, glen=267, tlen=495, kl=0, act_lr=0, ent=1.58]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  68%|██████▊   | 43/63 [15:51<07:03, 21.16s/it, pg=-0.00652, ret=0, glen=482, tlen=712, kl=0, act_lr=0, ent=1.46]Actor Train epoch [1/1]:  70%|██████▉   | 44/63 [15:51<06:41, 21.16s/it, pg=-0.00652, ret=0, glen=482, tlen=712, kl=0, act_lr=0, ent=1.46]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  70%|██████▉   | 44/63 [16:12<06:41, 21.16s/it, pg=0.129, ret=0, glen=472, tlen=688, kl=0, act_lr=0, ent=1.78]   Actor Train epoch [1/1]:  71%|███████▏  | 45/63 [16:12<06:20, 21.16s/it, pg=0.129, ret=0, glen=472, tlen=688, kl=0, act_lr=0, ent=1.78]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  71%|███████▏  | 45/63 [16:33<06:20, 21.16s/it, pg=0.0837, ret=0, glen=357, tlen=567, kl=0, act_lr=0, ent=1.73]Actor Train epoch [1/1]:  73%|███████▎  | 46/63 [16:33<05:59, 21.16s/it, pg=0.0837, ret=0, glen=357, tlen=567, kl=0, act_lr=0, ent=1.73]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  73%|███████▎  | 46/63 [16:54<05:59, 21.16s/it, pg=0.0396, ret=0, glen=270, tlen=485, kl=0, act_lr=0, ent=1.55]Actor Train epoch [1/1]:  75%|███████▍  | 47/63 [16:54<05:38, 21.16s/it, pg=0.0396, ret=0, glen=270, tlen=485, kl=0, act_lr=0, ent=1.55]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  75%|███████▍  | 47/63 [17:15<05:38, 21.16s/it, pg=-0.0147, ret=0, glen=798, tlen=1e+3, kl=0, act_lr=0, ent=1.7]Actor Train epoch [1/1]:  76%|███████▌  | 48/63 [17:15<05:17, 21.17s/it, pg=-0.0147, ret=0, glen=798, tlen=1e+3, kl=0, act_lr=0, ent=1.7]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  76%|███████▌  | 48/63 [17:36<05:17, 21.17s/it, pg=-0.0264, ret=0, glen=317, tlen=535, kl=0, act_lr=0, ent=1.54]Actor Train epoch [1/1]:  78%|███████▊  | 49/63 [17:36<04:56, 21.17s/it, pg=-0.0264, ret=0, glen=317, tlen=535, kl=0, act_lr=0, ent=1.54]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  78%|███████▊  | 49/63 [17:58<04:56, 21.17s/it, pg=-0.0757, ret=0, glen=516, tlen=725, kl=0, act_lr=0, ent=1.49]Actor Train epoch [1/1]:  79%|███████▉  | 50/63 [17:58<04:35, 21.16s/it, pg=-0.0757, ret=0, glen=516, tlen=725, kl=0, act_lr=0, ent=1.49]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  79%|███████▉  | 50/63 [18:19<04:35, 21.16s/it, pg=0.0483, ret=0, glen=378, tlen=602, kl=0, act_lr=0, ent=1.52] Actor Train epoch [1/1]:  81%|████████  | 51/63 [18:19<04:13, 21.17s/it, pg=0.0483, ret=0, glen=378, tlen=602, kl=0, act_lr=0, ent=1.52]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  81%|████████  | 51/63 [18:40<04:13, 21.17s/it, pg=0.104, ret=0, glen=741, tlen=952, kl=0, act_lr=0, ent=1.28] Actor Train epoch [1/1]:  83%|████████▎ | 52/63 [18:40<03:52, 21.16s/it, pg=0.104, ret=0, glen=741, tlen=952, kl=0, act_lr=0, ent=1.28]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  83%|████████▎ | 52/63 [19:01<03:52, 21.16s/it, pg=-0.0483, ret=0, glen=461, tlen=672, kl=0, act_lr=0, ent=1.59]Actor Train epoch [1/1]:  84%|████████▍ | 53/63 [19:01<03:31, 21.16s/it, pg=-0.0483, ret=0, glen=461, tlen=672, kl=0, act_lr=0, ent=1.59]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  84%|████████▍ | 53/63 [19:22<03:31, 21.16s/it, pg=-0.0159, ret=0, glen=851, tlen=1.06e+3, kl=0, act_lr=0, ent=1.36]Actor Train epoch [1/1]:  86%|████████▌ | 54/63 [19:22<03:10, 21.20s/it, pg=-0.0159, ret=0, glen=851, tlen=1.06e+3, kl=0, act_lr=0, ent=1.36]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  86%|████████▌ | 54/63 [19:44<03:10, 21.20s/it, pg=0.0115, ret=0, glen=561, tlen=767, kl=0, act_lr=0, ent=2.03]     Actor Train epoch [1/1]:  87%|████████▋ | 55/63 [19:44<02:49, 21.20s/it, pg=0.0115, ret=0, glen=561, tlen=767, kl=0, act_lr=0, ent=2.03]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  87%|████████▋ | 55/63 [20:05<02:49, 21.20s/it, pg=-0.0639, ret=0, glen=305, tlen=513, kl=0, act_lr=0, ent=1.53]Actor Train epoch [1/1]:  89%|████████▉ | 56/63 [20:05<02:28, 21.25s/it, pg=-0.0639, ret=0, glen=305, tlen=513, kl=0, act_lr=0, ent=1.53]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  89%|████████▉ | 56/63 [20:26<02:28, 21.25s/it, pg=0.0158, ret=0, glen=366, tlen=590, kl=0, act_lr=0, ent=1.59] Actor Train epoch [1/1]:  90%|█████████ | 57/63 [20:26<02:07, 21.29s/it, pg=0.0158, ret=0, glen=366, tlen=590, kl=0, act_lr=0, ent=1.59]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  90%|█████████ | 57/63 [20:48<02:07, 21.29s/it, pg=0.0151, ret=0, glen=627, tlen=837, kl=0, act_lr=0, ent=1.11]Actor Train epoch [1/1]:  92%|█████████▏| 58/63 [20:48<01:46, 21.25s/it, pg=0.0151, ret=0, glen=627, tlen=837, kl=0, act_lr=0, ent=1.11]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  92%|█████████▏| 58/63 [21:09<01:46, 21.25s/it, pg=-0.019, ret=0, glen=628, tlen=849, kl=0, act_lr=0, ent=2.5] Actor Train epoch [1/1]:  94%|█████████▎| 59/63 [21:09<01:24, 21.23s/it, pg=-0.019, ret=0, glen=628, tlen=849, kl=0, act_lr=0, ent=2.5]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  94%|█████████▎| 59/63 [21:30<01:24, 21.23s/it, pg=-0.015, ret=0, glen=820, tlen=1.05e+3, kl=0, act_lr=0, ent=2.09]Actor Train epoch [1/1]:  95%|█████████▌| 60/63 [21:30<01:03, 21.21s/it, pg=-0.015, ret=0, glen=820, tlen=1.05e+3, kl=0, act_lr=0, ent=2.09]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  95%|█████████▌| 60/63 [21:51<01:03, 21.21s/it, pg=-0.0353, ret=0, glen=608, tlen=820, kl=0, act_lr=0, ent=1.29]   Actor Train epoch [1/1]:  97%|█████████▋| 61/63 [21:51<00:42, 21.19s/it, pg=-0.0353, ret=0, glen=608, tlen=820, kl=0, act_lr=0, ent=1.29]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  97%|█████████▋| 61/63 [22:12<00:42, 21.19s/it, pg=0.0564, ret=0, glen=356, tlen=563, kl=0, act_lr=0, ent=1.38] Actor Train epoch [1/1]:  98%|█████████▊| 62/63 [22:12<00:21, 21.18s/it, pg=0.0564, ret=0, glen=356, tlen=563, kl=0, act_lr=0, ent=1.38]
[36m(PolicyRayActorBase pid=3701267)[0m Actor Train epoch [1/1]:  98%|█████████▊| 62/63 [22:33<00:21, 21.18s/it, pg=-0.0311, ret=0, glen=516, tlen=726, kl=0, act_lr=2e-8, ent=2.06]Actor Train epoch [1/1]:  98%|█████████▊| 62/63 [22:33<00:21, 21.84s/it, pg=-0.0311, ret=0, glen=516, tlen=726, kl=0, act_lr=2e-8, ent=2.06]
[36m(PolicyRayActorBase pid=3701267)[0m [2025-07-14 17:11:34,220] [WARNING] [stage3.py:2118:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
2025-07-14 17:11:34.234 | INFO     | orz.ppo.trainer:ppo_local_train_policy:732 - Policy model training, time cost: 1354.12s
2025-07-14 17:11:34.523 | INFO     | orz.ppo.trainer:ppo_local_train_policy:739 - Backload vllm engines to gpu, time cost: 0.23s
2025-07-14 17:11:34.523 | INFO     | orz.ppo.trainer:train:148 - Actor model training, time cost: 1354.43s
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/a/anokhin/Open-Reasoner-Zero/playground/orz_0p5b_ppo.py", line 141, in <module>
    asyncio.run(exp.run())
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/python/3.12.4/lib/python3.12/asyncio/runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/python/3.12.4/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/python/3.12.4/lib/python3.12/asyncio/base_events.py", line 687, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/home/a/anokhin/Open-Reasoner-Zero/orz/exps/examples/ppo/ppo_base_exp.py", line 231, in run
    await self.trainer.train()
  File "/home/a/anokhin/Open-Reasoner-Zero/orz/ppo/trainer.py", line 150, in train
    status = await self.ppo_local_train_policy(policy_buffers, self.global_step)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/a/anokhin/Open-Reasoner-Zero/orz/ppo/trainer.py", line 740, in ppo_local_train_policy
    await self._backload_vllm_engines()
  File "/home/a/anokhin/Open-Reasoner-Zero/orz/ppo/trainer.py", line 1289, in _backload_vllm_engines
    await asyncio.gather(*backload_tasks)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/python/3.12.4/lib/python3.12/asyncio/tasks.py", line 684, in _wrap_awaitable
    return await awaitable
           ^^^^^^^^^^^^^^^
ray.exceptions.RayTaskError(OutOfMemoryError): [36mray::LLMActor.backload_to_gpu()[39m (pid=3700665, ip=10.224.3.42, actor_id=fb3fe02e8f8243e575c4e1aa01000000, repr=<orz.exp_engine.accelerators.inference.vllm_engine.LLMActor object at 0x7343355c7800>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/a/anokhin/Open-Reasoner-Zero/orz/exp_engine/accelerators/inference/vllm_engine.py", line 76, in backload_to_gpu
    self.llm.llm_engine.model_executor.driver_worker.load_gpu()
  File "/home/a/anokhin/Open-Reasoner-Zero/orz/exp_engine/accelerators/inference/vllm_worker_wrap.py", line 100, in load_gpu
    super()._init_cache_engine()
  File "/home/a/anokhin/envs/reasoner3.12/lib/python3.12/site-packages/vllm/worker/worker.py", line 312, in _init_cache_engine
    CacheEngine(self.cache_config, self.model_config,
  File "/home/a/anokhin/envs/reasoner3.12/lib/python3.12/site-packages/vllm/worker/cache_engine.py", line 69, in __init__
    self.gpu_cache = self._allocate_kv_cache(
                     ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/a/anokhin/envs/reasoner3.12/lib/python3.12/site-packages/vllm/worker/cache_engine.py", line 103, in _allocate_kv_cache
    layer_kv_cache = torch.zeros(alloc_shape,
                     ^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.41 GiB. GPU 0 has a total capacity of 79.19 GiB of which 1.15 GiB is free. Including non-PyTorch memory, this process has 66.54 GiB memory in use. Process 3701438 has 8.45 GiB memory in use. Process 3702112 has 1.35 GiB memory in use. Process 3702760 has 1.66 GiB memory in use. Of the allocated memory 65.78 GiB is allocated by PyTorch, and 101.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/a/anokhin/Open-Reasoner-Zero/playground/orz_0p5b_ppo.py", line 141, in <module>
    asyncio.run(exp.run())
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/python/3.12.4/lib/python3.12/asyncio/runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/python/3.12.4/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/python/3.12.4/lib/python3.12/asyncio/base_events.py", line 687, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/home/a/anokhin/Open-Reasoner-Zero/orz/exps/examples/ppo/ppo_base_exp.py", line 231, in run
    await self.trainer.train()
  File "/home/a/anokhin/Open-Reasoner-Zero/orz/ppo/trainer.py", line 150, in train
    status = await self.ppo_local_train_policy(policy_buffers, self.global_step)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/a/anokhin/Open-Reasoner-Zero/orz/ppo/trainer.py", line 740, in ppo_local_train_policy
    await self._backload_vllm_engines()
  File "/home/a/anokhin/Open-Reasoner-Zero/orz/ppo/trainer.py", line 1289, in _backload_vllm_engines
    await asyncio.gather(*backload_tasks)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v4/Compiler/gcccore/python/3.12.4/lib/python3.12/asyncio/tasks.py", line 684, in _wrap_awaitable
    return await awaitable
           ^^^^^^^^^^^^^^^
ray.exceptions.RayTaskError(OutOfMemoryError): [36mray::LLMActor.backload_to_gpu()[39m (pid=3700665, ip=10.224.3.42, actor_id=fb3fe02e8f8243e575c4e1aa01000000, repr=<orz.exp_engine.accelerators.inference.vllm_engine.LLMActor object at 0x7343355c7800>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/a/anokhin/Open-Reasoner-Zero/orz/exp_engine/accelerators/inference/vllm_engine.py", line 76, in backload_to_gpu
    self.llm.llm_engine.model_executor.driver_worker.load_gpu()
  File "/home/a/anokhin/Open-Reasoner-Zero/orz/exp_engine/accelerators/inference/vllm_worker_wrap.py", line 100, in load_gpu
    super()._init_cache_engine()
  File "/home/a/anokhin/envs/reasoner3.12/lib/python3.12/site-packages/vllm/worker/worker.py", line 312, in _init_cache_engine
    CacheEngine(self.cache_config, self.model_config,
  File "/home/a/anokhin/envs/reasoner3.12/lib/python3.12/site-packages/vllm/worker/cache_engine.py", line 69, in __init__
    self.gpu_cache = self._allocate_kv_cache(
                     ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/a/anokhin/envs/reasoner3.12/lib/python3.12/site-packages/vllm/worker/cache_engine.py", line 103, in _allocate_kv_cache
    layer_kv_cache = torch.zeros(alloc_shape,
                     ^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.41 GiB. GPU 0 has a total capacity of 79.19 GiB of which 1.15 GiB is free. Including non-PyTorch memory, this process has 66.54 GiB memory in use. Process 3701438 has 8.45 GiB memory in use. Process 3702112 has 1.35 GiB memory in use. Process 3702760 has 1.66 GiB memory in use. Of the allocated memory 65.78 GiB is allocated by PyTorch, and 101.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: 
wandb: Run history:
wandb:                  avg_correct_num_tokens ▁
wandb:                      avg_custom_rewards ▁
wandb:                avg_incorrect_num_tokens ▁
wandb:                                  avg_kl ▁
wandb:                              avg_kl_max ▁
wandb:                      avg_non_stop_count ▁
wandb:                          avg_num_tokens ▁
wandb:                           avg_orm_score ▁
wandb:                           avg_pass_at_n ▁
wandb:                      avg_raw_advantages ▁
wandb:                  avg_raw_advantages_abs ▁
wandb:                         avg_raw_rewards ▁
wandb:            avg_reflection_pattern_score ▁
wandb:                        avg_repeat_score ▁
wandb:                     avg_response_length ▁
wandb:                             critic_loss ▁
wandb:                     critic_update_steps ▁
wandb:                 evals/aime2024/accuracy ▁
wandb:     evals/aime2024/response_len_in_char ▁
wandb:                     evals/eval_accuracy ▁
wandb:             evals/gpqa_diamond/accuracy ▁
wandb: evals/gpqa_diamond/response_len_in_char ▁
wandb:                  evals/math500/accuracy ▁
wandb:      evals/math500/response_len_in_char ▁
wandb:                             global_step ▁
wandb:                          policy_entropy ▁
wandb:                     policy_update_steps ▁
wandb:                          ppo_clip_count ▁
wandb:                  std_correct_num_tokens ▁
wandb:                std_incorrect_num_tokens ▁
wandb:                          std_num_tokens ▁
wandb: 
wandb: Run summary:
wandb:                  avg_correct_num_tokens 41.0
wandb:                      avg_custom_rewards 0.00011
wandb:                avg_incorrect_num_tokens 350.29019
wandb:                                  avg_kl 0.0
wandb:                              avg_kl_max 0.0
wandb:                      avg_non_stop_count 0.00183
wandb:                          avg_num_tokens 350.25244
wandb:                           avg_orm_score 0.0
wandb:                           avg_pass_at_n 0.00781
wandb:                      avg_raw_advantages 0.13297
wandb:                  avg_raw_advantages_abs 0.19884
wandb:                         avg_raw_rewards 0.00011
wandb:            avg_reflection_pattern_score 0.01343
wandb:                        avg_repeat_score 0.02648
wandb:                     avg_response_length 482.0419
wandb:                             critic_loss 0.0057
wandb:                     critic_update_steps 12.0
wandb:                 evals/aime2024/accuracy 0.0
wandb:     evals/aime2024/response_len_in_char 987.09998
wandb:                     evals/eval_accuracy 0.0
wandb:             evals/gpqa_diamond/accuracy 0.0
wandb: evals/gpqa_diamond/response_len_in_char 950.06567
wandb:                  evals/math500/accuracy 0.0
wandb:      evals/math500/response_len_in_char 1000.04999
wandb:                             global_step 0
wandb:                          policy_entropy 1.63622
wandb:                     policy_update_steps 1.0
wandb:                          ppo_clip_count 0.0
wandb:                  std_correct_num_tokens 0.0
wandb:                std_incorrect_num_tokens 668.77539
wandb:                          std_num_tokens 668.74335
wandb: 
wandb: 🚀 View run orz_0p5b_ppo_8gpu_v2 at: https://wandb.ai/irina-rish/open-reasoner-zero/runs/wrzopn3r
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: orz_logs/orz_0p5b_ppo/wandb/run-20250714_155458-wrzopn3r/logs

======== GPU REPORT ========

==============NVSMI LOG==============

Timestamp                                 : Mon Jul 14 17:11:53 2025
Driver Version                            : 570.133.20
CUDA Version                              : 12.8

Attached GPUs                             : 4
GPU 00000000:4E:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes
        Process ID                        : 3701439
            GPU Utilization               : 11 %
            Memory Utilization            : 0 %
            Max memory usage              : 31556 MiB
            Time                          : 4538571 ms
            Is Running                    : 0
        Process ID                        : 3702113
            GPU Utilization               : 39 %
            Memory Utilization            : 0 %
            Max memory usage              : 7374 MiB
            Time                          : 4531879 ms
            Is Running                    : 0
        Process ID                        : 3700666
            GPU Utilization               : 1 %
            Memory Utilization            : 0 %
            Max memory usage              : 71024 MiB
            Time                          : 4603578 ms
            Is Running                    : 0
        Process ID                        : 3701267
            GPU Utilization               : 40 %
            Memory Utilization            : 0 %
            Max memory usage              : 42082 MiB
            Time                          : 0 ms
            Is Running                    : 1

GPU 00000000:5F:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes
        Process ID                        : 3702110
            GPU Utilization               : 11 %
            Memory Utilization            : 0 %
            Max memory usage              : 8780 MiB
            Time                          : 4530889 ms
            Is Running                    : 0
        Process ID                        : 3702761
            GPU Utilization               : 39 %
            Memory Utilization            : 0 %
            Max memory usage              : 7582 MiB
            Time                          : 4523779 ms
            Is Running                    : 0
        Process ID                        : 3700668
            GPU Utilization               : 0 %
            Memory Utilization            : 0 %
            Max memory usage              : 71024 MiB
            Time                          : 4602876 ms
            Is Running                    : 0
        Process ID                        : 3701440
            GPU Utilization               : 40 %
            Memory Utilization            : 0 %
            Max memory usage              : 41996 MiB
            Time                          : 0 ms
            Is Running                    : 1

GPU 00000000:CB:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes
        Process ID                        : 3702112
            GPU Utilization               : 11 %
            Memory Utilization            : 0 %
            Max memory usage              : 39872 MiB
            Time                          : 4531494 ms
            Is Running                    : 0
        Process ID                        : 3701438
            GPU Utilization               : 40 %
            Memory Utilization            : 0 %
            Max memory usage              : 42408 MiB
            Time                          : 4539173 ms
            Is Running                    : 0
        Process ID                        : 3700665
            GPU Utilization               : 0 %
            Memory Utilization            : 0 %
            Max memory usage              : 71026 MiB
            Time                          : 4603535 ms
            Is Running                    : 0
        Process ID                        : 3702760
            GPU Utilization               : 39 %
            Memory Utilization            : 0 %
            Max memory usage              : 7412 MiB
            Time                          : 4525995 ms
            Is Running                    : 0

GPU 00000000:DB:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes
        Process ID                        : 3701441
            GPU Utilization               : 40 %
            Memory Utilization            : 0 %
            Max memory usage              : 41714 MiB
            Time                          : 4537850 ms
            Is Running                    : 0
        Process ID                        : 3702111
            GPU Utilization               : 11 %
            Memory Utilization            : 0 %
            Max memory usage              : 37556 MiB
            Time                          : 4531593 ms
            Is Running                    : 0
        Process ID                        : 3702762
            GPU Utilization               : 39 %
            Memory Utilization            : 0 %
            Max memory usage              : 7286 MiB
            Time                          : 4523953 ms
            Is Running                    : 0
        Process ID                        : 3700667
            GPU Utilization               : 0 %
            Memory Utilization            : 0 %
            Max memory usage              : 71024 MiB
            Time                          : 4604438 ms
            Is Running                    : 0

Mon Jul 14 17:11:54 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:4E:00.0 Off |                    0 |
| N/A   42C    P0            134W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  |   00000000:5F:00.0 Off |                    0 |
| N/A   41C    P0            128W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  |   00000000:CB:00.0 Off |                    0 |
| N/A   42C    P0            128W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  |   00000000:DB:00.0 Off |                    0 |
| N/A   42C    P0            132W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

======== GPU REPORT ========

==============NVSMI LOG==============

Timestamp                                 : Mon Jul 14 17:11:56 2025
Driver Version                            : 570.133.20
CUDA Version                              : 12.8

Attached GPUs                             : 4
GPU 00000000:4E:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes
        Process ID                        : 1560953
            GPU Utilization               : 39 %
            Memory Utilization            : 0 %
            Max memory usage              : 7350 MiB
            Time                          : 4523871 ms
            Is Running                    : 0
        Process ID                        : 1560293
            GPU Utilization               : 11 %
            Memory Utilization            : 0 %
            Max memory usage              : 25786 MiB
            Time                          : 4531420 ms
            Is Running                    : 0
        Process ID                        : 1559633
            GPU Utilization               : 40 %
            Memory Utilization            : 0 %
            Max memory usage              : 42134 MiB
            Time                          : 4540050 ms
            Is Running                    : 0
        Process ID                        : 1559112
            GPU Utilization               : 0 %
            Memory Utilization            : 0 %
            Max memory usage              : 71024 MiB
            Time                          : 4603608 ms
            Is Running                    : 0

GPU 00000000:5F:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes
        Process ID                        : 1560307
            GPU Utilization               : 11 %
            Memory Utilization            : 0 %
            Max memory usage              : 14566 MiB
            Time                          : 4531046 ms
            Is Running                    : 0
        Process ID                        : 1560954
            GPU Utilization               : 39 %
            Memory Utilization            : 0 %
            Max memory usage              : 8130 MiB
            Time                          : 4524414 ms
            Is Running                    : 0
        Process ID                        : 1559111
            GPU Utilization               : 0 %
            Memory Utilization            : 0 %
            Max memory usage              : 71024 MiB
            Time                          : 4603402 ms
            Is Running                    : 0
        Process ID                        : 1559635
            GPU Utilization               : 40 %
            Memory Utilization            : 0 %
            Max memory usage              : 41674 MiB
            Time                          : 4541727 ms
            Is Running                    : 0

GPU 00000000:CB:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes
        Process ID                        : 1560308
            GPU Utilization               : 11 %
            Memory Utilization            : 0 %
            Max memory usage              : 20294 MiB
            Time                          : 4530846 ms
            Is Running                    : 0
        Process ID                        : 1559636
            GPU Utilization               : 40 %
            Memory Utilization            : 0 %
            Max memory usage              : 42394 MiB
            Time                          : 4540050 ms
            Is Running                    : 0
        Process ID                        : 1559114
            GPU Utilization               : 0 %
            Memory Utilization            : 0 %
            Max memory usage              : 71024 MiB
            Time                          : 4604200 ms
            Is Running                    : 0
        Process ID                        : 1560956
            GPU Utilization               : 39 %
            Memory Utilization            : 0 %
            Max memory usage              : 7054 MiB
            Time                          : 4526524 ms
            Is Running                    : 0

GPU 00000000:DB:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes
        Process ID                        : 1560306
            GPU Utilization               : 11 %
            Memory Utilization            : 0 %
            Max memory usage              : 14562 MiB
            Time                          : 4530515 ms
            Is Running                    : 0
        Process ID                        : 1559113
            GPU Utilization               : 0 %
            Memory Utilization            : 0 %
            Max memory usage              : 71026 MiB
            Time                          : 4603317 ms
            Is Running                    : 0
        Process ID                        : 1560955
            GPU Utilization               : 39 %
            Memory Utilization            : 0 %
            Max memory usage              : 7406 MiB
            Time                          : 4525601 ms
            Is Running                    : 0
        Process ID                        : 1559634
            GPU Utilization               : 40 %
            Memory Utilization            : 0 %
            Max memory usage              : 39742 MiB
            Time                          : 4540514 ms
            Is Running                    : 0

Mon Jul 14 17:11:57 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:4E:00.0 Off |                    0 |
| N/A   40C    P0             71W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  |   00000000:5F:00.0 Off |                    0 |
| N/A   39C    P0             71W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  |   00000000:CB:00.0 Off |                    0 |
| N/A   39C    P0             72W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  |   00000000:DB:00.0 Off |                    0 |
| N/A   40C    P0             71W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

======== GPU REPORT ========

==============NVSMI LOG==============

Timestamp                                 : Mon Jul 14 17:11:57 2025
Driver Version                            : 570.133.20
CUDA Version                              : 12.8

Attached GPUs                             : 4
GPU 00000000:4E:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes
        Process ID                        : 3701439
            GPU Utilization               : 11 %
            Memory Utilization            : 0 %
            Max memory usage              : 31556 MiB
            Time                          : 4538571 ms
            Is Running                    : 0
        Process ID                        : 3702113
            GPU Utilization               : 39 %
            Memory Utilization            : 0 %
            Max memory usage              : 7374 MiB
            Time                          : 4531879 ms
            Is Running                    : 0
        Process ID                        : 3700666
            GPU Utilization               : 1 %
            Memory Utilization            : 0 %
            Max memory usage              : 71024 MiB
            Time                          : 4603578 ms
            Is Running                    : 0
        Process ID                        : 3701267
            GPU Utilization               : 40 %
            Memory Utilization            : 0 %
            Max memory usage              : 42082 MiB
            Time                          : 4548321 ms
            Is Running                    : 0

GPU 00000000:5F:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes
        Process ID                        : 3702110
            GPU Utilization               : 11 %
            Memory Utilization            : 0 %
            Max memory usage              : 8780 MiB
            Time                          : 4530889 ms
            Is Running                    : 0
        Process ID                        : 3702761
            GPU Utilization               : 39 %
            Memory Utilization            : 0 %
            Max memory usage              : 7582 MiB
            Time                          : 4523779 ms
            Is Running                    : 0
        Process ID                        : 3700668
            GPU Utilization               : 0 %
            Memory Utilization            : 0 %
            Max memory usage              : 71024 MiB
            Time                          : 4602876 ms
            Is Running                    : 0
        Process ID                        : 3701440
            GPU Utilization               : 40 %
            Memory Utilization            : 0 %
            Max memory usage              : 41996 MiB
            Time                          : 4541960 ms
            Is Running                    : 0

GPU 00000000:CB:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes
        Process ID                        : 3702112
            GPU Utilization               : 11 %
            Memory Utilization            : 0 %
            Max memory usage              : 39872 MiB
            Time                          : 4531494 ms
            Is Running                    : 0
        Process ID                        : 3701438
            GPU Utilization               : 40 %
            Memory Utilization            : 0 %
            Max memory usage              : 42408 MiB
            Time                          : 4539173 ms
            Is Running                    : 0
        Process ID                        : 3700665
            GPU Utilization               : 0 %
            Memory Utilization            : 0 %
            Max memory usage              : 71026 MiB
            Time                          : 4603535 ms
            Is Running                    : 0
        Process ID                        : 3702760
            GPU Utilization               : 39 %
            Memory Utilization            : 0 %
            Max memory usage              : 7412 MiB
            Time                          : 4525995 ms
            Is Running                    : 0

GPU 00000000:DB:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes
        Process ID                        : 3701441
            GPU Utilization               : 40 %
            Memory Utilization            : 0 %
            Max memory usage              : 41714 MiB
            Time                          : 4537850 ms
            Is Running                    : 0
        Process ID                        : 3702111
            GPU Utilization               : 11 %
            Memory Utilization            : 0 %
            Max memory usage              : 37556 MiB
            Time                          : 4531593 ms
            Is Running                    : 0
        Process ID                        : 3702762
            GPU Utilization               : 39 %
            Memory Utilization            : 0 %
            Max memory usage              : 7286 MiB
            Time                          : 4523953 ms
            Is Running                    : 0
        Process ID                        : 3700667
            GPU Utilization               : 0 %
            Memory Utilization            : 0 %
            Max memory usage              : 71024 MiB
            Time                          : 4604438 ms
            Is Running                    : 0

Mon Jul 14 17:11:58 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:4E:00.0 Off |                    0 |
| N/A   40C    P0             74W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  |   00000000:5F:00.0 Off |                    0 |
| N/A   39C    P0             72W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  |   00000000:CB:00.0 Off |                    0 |
| N/A   40C    P0             72W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  |   00000000:DB:00.0 Off |                    0 |
| N/A   40C    P0             71W /  700W |       0MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
